{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 곱창집 입지 분석 데이터 정제\n",
    "# 02-1_data_cleaning.ipynb\n",
    "# \n",
    "# 목적: 마스터 데이터셋의 품질 문제 해결\n",
    "#       - 업종별 중복 제거 (471K → 1.6K)\n",
    "#       - 좌표 정보 복구\n",
    "#       - 정확한 상권별 집계\n",
    "\n",
    "# ================================================================================\n",
    "# 📚 라이브러리 임포트\n",
    "# ================================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"🧹 곱창집 입지 분석 데이터 정제 시작!\")\n",
    "print(f\"⏰ 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 📂 원본 데이터 다시 로드 (정제용)\n",
    "# ================================================================================\n",
    "\n",
    "print(\"📂 원본 데이터 다시 로드 (정제용)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 데이터 경로\n",
    "DATA_PATH = Path(\"../data\")\n",
    "RAW_PATH = DATA_PATH / \"raw\"\n",
    "\n",
    "# 1. 기준 데이터: 상권 경계 (1,650개 상권)\n",
    "boundary_df = pd.read_csv(DATA_PATH / \"boundary/boundary_all.csv\", encoding='utf-8')\n",
    "print(f\"📍 상권 경계: {boundary_df.shape} (기준)\")\n",
    "\n",
    "# 2. 최신 분기 데이터들 로드\n",
    "flow_df = pd.read_csv(RAW_PATH / \"flow/flow_all.csv\", encoding='utf-8')\n",
    "latest_quarter = flow_df['기준_년분기_코드'].max()\n",
    "flow_latest = flow_df[flow_df['기준_년분기_코드'] == latest_quarter].copy()\n",
    "print(f\"👥 유동인구 ({latest_quarter}): {flow_latest.shape}\")\n",
    "\n",
    "# 3. 매출 데이터 (문제의 핵심)\n",
    "sales_df = pd.read_csv(RAW_PATH / \"sales/sales_all.csv\", encoding='utf-8')\n",
    "sales_latest = sales_df[sales_df['기준_년분기_코드'] == latest_quarter].copy()\n",
    "print(f\"💰 매출 원본 ({latest_quarter}): {sales_latest.shape} ← 문제!\")\n",
    "\n",
    "# 4. 상주인구\n",
    "resident_df = pd.read_csv(RAW_PATH / \"resident/resident_all.csv\", encoding='utf-8')\n",
    "print(f\"🏠 상주인구: {resident_df.shape}\")\n",
    "\n",
    "# 5. 소득·소비\n",
    "income_df = pd.read_csv(RAW_PATH / \"income_exp/income_all.csv\", encoding='utf-8')\n",
    "income_latest = income_df[income_df['기준_년분기_코드'] == latest_quarter].copy()\n",
    "print(f\"💳 소득·소비 ({latest_quarter}): {income_latest.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🔍 문제 진단: 중복 데이터 분석\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🔍 문제 진단: 중복 데이터 분석\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 매출 데이터 중복 원인 분석\n",
    "print(\"1️⃣ 매출 데이터 구조 분석:\")\n",
    "print(f\"   📊 총 행수: {len(sales_latest):,}개\")\n",
    "print(f\"   🏪 고유 상권수: {sales_latest['상권_코드'].nunique():,}개\")\n",
    "\n",
    "# 업종별 분석\n",
    "if '서비스_업종_코드_명' in sales_latest.columns:\n",
    "    service_counts = sales_latest['서비스_업종_코드_명'].value_counts()\n",
    "    print(f\"   🏷️ 업종 종류: {len(service_counts)}개\")\n",
    "    print(f\"   📋 주요 업종:\")\n",
    "    for i, (service, count) in enumerate(service_counts.head(5).items()):\n",
    "        print(f\"      {i+1}. {service}: {count:,}개\")\n",
    "\n",
    "# 상권별 행수 분석\n",
    "district_counts = sales_latest['상권_코드'].value_counts()\n",
    "print(f\"\\n   📊 상권별 평균 행수: {district_counts.mean():.1f}개\")\n",
    "print(f\"   📊 상권별 최대 행수: {district_counts.max()}개\")\n",
    "\n",
    "# 2. 기타 데이터 중복 확인\n",
    "print(f\"\\n2️⃣ 기타 데이터 중복 확인:\")\n",
    "datasets = {\n",
    "    'boundary': boundary_df,\n",
    "    'flow_latest': flow_latest,\n",
    "    'resident': resident_df,\n",
    "    'income_latest': income_latest\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    if '상권_코드' in df.columns:\n",
    "        unique_districts = df['상권_코드'].nunique()\n",
    "        total_rows = len(df)\n",
    "        print(f\"   {name:12s}: {total_rows:5,}행 / {unique_districts:4,}개 상권 = {total_rows/unique_districts if unique_districts > 0 else 0:4.1f}행/상권\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🔧 데이터 정제 1단계: 업종별 집계\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🔧 데이터 정제 1단계: 업종별 집계\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 매출 데이터 상권별 집계\n",
    "print(\"1️⃣ 매출 데이터 상권별 집계:\")\n",
    "\n",
    "# 매출 관련 컬럼 식별\n",
    "sales_amount_cols = [col for col in sales_latest.columns if '매출_금액' in col]\n",
    "sales_count_cols = [col for col in sales_latest.columns if '매출_건수' in col]\n",
    "\n",
    "print(f\"   📋 매출금액 컬럼: {len(sales_amount_cols)}개\")\n",
    "print(f\"   📋 매출건수 컬럼: {len(sales_count_cols)}개\")\n",
    "\n",
    "# 상권별 집계 (업종별 합계)\n",
    "sales_agg_dict = {}\n",
    "\n",
    "# 매출금액 합계\n",
    "for col in sales_amount_cols:\n",
    "    sales_agg_dict[col] = 'sum'\n",
    "\n",
    "# 매출건수 합계  \n",
    "for col in sales_count_cols:\n",
    "    sales_agg_dict[col] = 'sum'\n",
    "\n",
    "# 기본 정보는 첫 번째 값 사용\n",
    "basic_cols = ['상권_구분_코드', '상권_구분_코드_명', '상권_코드_명']\n",
    "for col in basic_cols:\n",
    "    if col in sales_latest.columns:\n",
    "        sales_agg_dict[col] = 'first'\n",
    "\n",
    "# 집계 실행\n",
    "sales_clean = sales_latest.groupby('상권_코드').agg(sales_agg_dict).reset_index()\n",
    "\n",
    "print(f\"   📊 집계 전: {len(sales_latest):,}행\")\n",
    "print(f\"   📊 집계 후: {len(sales_clean):,}행\")\n",
    "print(f\"   ✅ 상권 수 일치: {len(sales_clean) == sales_latest['상권_코드'].nunique()}\")\n",
    "\n",
    "# 2. 기타 데이터도 중복 제거 (혹시 모를 중복)\n",
    "print(f\"\\n2️⃣ 기타 데이터 중복 제거:\")\n",
    "\n",
    "# 유동인구 (이미 깨끗해야 하지만 확인)\n",
    "flow_clean = flow_latest.drop_duplicates(subset=['상권_코드']).copy()\n",
    "print(f\"   👥 유동인구: {len(flow_latest):,} → {len(flow_clean):,}개\")\n",
    "\n",
    "# 상주인구 - 상권별 집계 (연령대별 합계)\n",
    "resident_pop_cols = [col for col in resident_df.columns if '상주인구_수' in col]\n",
    "if not resident_pop_cols:\n",
    "    resident_pop_cols = [col for col in resident_df.columns if '인구_수' in col]\n",
    "\n",
    "if resident_pop_cols:\n",
    "    resident_agg = {}\n",
    "    for col in resident_pop_cols:\n",
    "        resident_agg[col] = 'sum'\n",
    "    \n",
    "    # market_code 기준 집계\n",
    "    if 'market_code' in resident_df.columns:\n",
    "        resident_clean = resident_df.groupby('market_code').agg(resident_agg).reset_index()\n",
    "        resident_clean['상권_코드'] = resident_clean['market_code']  # 컬럼명 통일\n",
    "    else:\n",
    "        resident_clean = resident_df.copy()\n",
    "        \n",
    "    print(f\"   🏠 상주인구: {len(resident_df):,} → {len(resident_clean):,}개\")\n",
    "else:\n",
    "    resident_clean = resident_df.copy()\n",
    "    print(f\"   🏠 상주인구: 집계 컬럼 없음 ({len(resident_clean):,}개 유지)\")\n",
    "\n",
    "# 소득·소비 중복 제거\n",
    "income_clean = income_latest.drop_duplicates(subset=['상권_코드']).copy()\n",
    "print(f\"   💳 소득·소비: {len(income_latest):,} → {len(income_clean):,}개\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🗺️ 데이터 정제 2단계: 좌표 정보 복구\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🗺️ 데이터 정제 2단계: 좌표 정보 복구\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 좌표 컬럼 재탐지\n",
    "print(\"1️⃣ 좌표 컬럼 재탐지:\")\n",
    "coord_columns = [col for col in boundary_df.columns if any(keyword in col.lower() \n",
    "                for keyword in ['x', 'y', '경도', '위도', 'lng', 'lat', '좌표'])]\n",
    "\n",
    "print(f\"   📍 좌표 관련 컬럼: {coord_columns}\")\n",
    "\n",
    "# 좌표 데이터 확인\n",
    "for col in coord_columns:\n",
    "    sample_values = boundary_df[col].dropna().head(5).tolist()\n",
    "    print(f\"      {col}: {sample_values}\")\n",
    "\n",
    "# 2. 경도/위도 식별\n",
    "lng_col = None\n",
    "lat_col = None\n",
    "\n",
    "# 경도 (X좌표, 동경)\n",
    "for col in coord_columns:\n",
    "    if any(keyword in col.lower() for keyword in ['x', '경도', 'lng', 'lon']):\n",
    "        lng_col = col\n",
    "        break\n",
    "\n",
    "# 위도 (Y좌표, 북위)  \n",
    "for col in coord_columns:\n",
    "    if any(keyword in col.lower() for keyword in ['y', '위도', 'lat']):\n",
    "        lat_col = col\n",
    "        break\n",
    "\n",
    "if lng_col and lat_col:\n",
    "    print(f\"\\n   ✅ 경도 컬럼: {lng_col}\")\n",
    "    print(f\"   ✅ 위도 컬럼: {lat_col}\")\n",
    "    \n",
    "    # 좌표 유효성 검증\n",
    "    valid_lng = boundary_df[lng_col].notna()\n",
    "    valid_lat = boundary_df[lat_col].notna()\n",
    "    valid_coords = valid_lng & valid_lat\n",
    "    \n",
    "    print(f\"   📊 유효한 경도: {valid_lng.sum():,}개\")\n",
    "    print(f\"   📊 유효한 위도: {valid_lat.sum():,}개\") \n",
    "    print(f\"   📊 완전한 좌표: {valid_coords.sum():,}개\")\n",
    "    \n",
    "    # 좌표 범위 검증 (서울 지역)\n",
    "    if valid_coords.sum() > 0:\n",
    "        lng_range = [boundary_df.loc[valid_coords, lng_col].min(), \n",
    "                     boundary_df.loc[valid_coords, lng_col].max()]\n",
    "        lat_range = [boundary_df.loc[valid_coords, lat_col].min(), \n",
    "                     boundary_df.loc[valid_coords, lat_col].max()]\n",
    "        \n",
    "        print(f\"   📐 경도 범위: {lng_range[0]:.6f} ~ {lng_range[1]:.6f}\")\n",
    "        print(f\"   📐 위도 범위: {lat_range[0]:.6f} ~ {lat_range[1]:.6f}\")\n",
    "        \n",
    "        # 서울 좌표 범위 검증 (대략적)\n",
    "        seoul_lng_range = [126.7, 127.3]  # 서울 경도 범위\n",
    "        seoul_lat_range = [37.4, 37.7]    # 서울 위도 범위\n",
    "        \n",
    "        lng_valid = (lng_range[0] >= seoul_lng_range[0] and lng_range[1] <= seoul_lng_range[1])\n",
    "        lat_valid = (lat_range[0] >= seoul_lat_range[0] and lat_range[1] <= seoul_lat_range[1])\n",
    "        \n",
    "        if lng_valid and lat_valid:\n",
    "            print(f\"   ✅ 서울 지역 좌표 범위 적합\")\n",
    "        else:\n",
    "            print(f\"   ⚠️ 좌표 범위 확인 필요 (서울 지역 벗어남)\")\n",
    "else:\n",
    "    print(f\"   ❌ 경도/위도 컬럼을 찾을 수 없음\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🔗 데이터 정제 3단계: 깔끔한 마스터 데이터셋 재구축\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🔗 데이터 정제 3단계: 깔끔한 마스터 데이터셋 재구축\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 기준 데이터: 상권 경계 (좌표 포함)\n",
    "print(\"1️⃣ 기준 데이터 설정:\")\n",
    "master_clean = boundary_df.copy()\n",
    "\n",
    "# 상권코드 컬럼 통일\n",
    "if '상권_코드' in master_clean.columns:\n",
    "    master_clean['TRDAR_CD'] = master_clean['상권_코드']\n",
    "else:\n",
    "    print(\"   ❌ 상권_코드 컬럼 없음!\")\n",
    "\n",
    "print(f\"   📍 기준 상권: {len(master_clean):,}개\")\n",
    "\n",
    "# 2. 유동인구 조인 (17-24시 야간 계산 포함)\n",
    "print(f\"\\n2️⃣ 유동인구 데이터 조인:\")\n",
    "\n",
    "# 야간 유동인구 재계산\n",
    "def calculate_night_flow_clean(df):\n",
    "    \"\"\"17-24시 야간 유동인구 계산 (깔끔한 버전)\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 야간 유동인구 (17-24시)\n",
    "    df['야간_유동인구_17_24'] = (df['시간대_17_21_유동인구_수'] + \n",
    "                               df['시간대_21_24_유동인구_수'])\n",
    "    \n",
    "    # 야간 비율\n",
    "    df['야간_비율'] = df['야간_유동인구_17_24'] / df['총_유동인구_수']\n",
    "    \n",
    "    # 주말 vs 주중\n",
    "    df['주말_평균'] = (df['토요일_유동인구_수'] + df['일요일_유동인구_수']) / 2\n",
    "    df['주중_평균'] = (df['월요일_유동인구_수'] + df['화요일_유동인구_수'] + \n",
    "                     df['수요일_유동인구_수'] + df['목요일_유동인구_수'] + \n",
    "                     df['금요일_유동인구_수']) / 5\n",
    "    df['주말_프리미엄'] = df['주말_평균'] / df['주중_평균']\n",
    "    \n",
    "    return df\n",
    "\n",
    "flow_clean = calculate_night_flow_clean(flow_clean)\n",
    "\n",
    "# 상권코드 통일 후 조인\n",
    "flow_clean['TRDAR_CD'] = flow_clean['상권_코드']\n",
    "\n",
    "# 핵심 컬럼만 선택\n",
    "flow_key_cols = ['TRDAR_CD', '총_유동인구_수', '야간_유동인구_17_24', '야간_비율',\n",
    "                 '주말_평균', '주중_평균', '주말_프리미엄',\n",
    "                 '남성_유동인구_수', '여성_유동인구_수',\n",
    "                 '연령대_20_유동인구_수', '연령대_30_유동인구_수', '연령대_40_유동인구_수']\n",
    "\n",
    "available_flow_cols = [col for col in flow_key_cols if col in flow_clean.columns]\n",
    "flow_selected = flow_clean[available_flow_cols].copy()\n",
    "\n",
    "master_clean = master_clean.merge(flow_selected, on='TRDAR_CD', how='left')\n",
    "print(f\"   📊 유동인구 매칭: {(master_clean['총_유동인구_수'].notna().sum() / len(master_clean)):.1%}\")\n",
    "\n",
    "# 3. 매출 데이터 조인 (집계된 깔끔한 데이터)\n",
    "print(f\"\\n3️⃣ 매출 데이터 조인:\")\n",
    "sales_clean['TRDAR_CD'] = sales_clean['상권_코드']\n",
    "\n",
    "# 주요 매출 컬럼 선택\n",
    "main_sales_col = '당월_매출_금액' if '당월_매출_금액' in sales_clean.columns else sales_amount_cols[0]\n",
    "sales_clean['총_매출'] = sales_clean[main_sales_col]\n",
    "\n",
    "sales_selected = sales_clean[['TRDAR_CD', '총_매출']].copy()\n",
    "master_clean = master_clean.merge(sales_selected, on='TRDAR_CD', how='left')\n",
    "print(f\"   📊 매출 매칭: {(master_clean['총_매출'].notna().sum() / len(master_clean)):.1%}\")\n",
    "\n",
    "# 4. 상주인구 조인\n",
    "print(f\"\\n4️⃣ 상주인구 조인:\")\n",
    "if 'market_code' in resident_clean.columns:\n",
    "    resident_clean['TRDAR_CD'] = resident_clean['market_code']\n",
    "elif '상권_코드' in resident_clean.columns:\n",
    "    resident_clean['TRDAR_CD'] = resident_clean['상권_코드']\n",
    "\n",
    "# 총 상주인구 계산\n",
    "resident_pop_cols = [col for col in resident_clean.columns if '인구_수' in col]\n",
    "if len(resident_pop_cols) > 1:\n",
    "    resident_clean['총_상주인구'] = resident_clean[resident_pop_cols].sum(axis=1)\n",
    "elif len(resident_pop_cols) == 1:\n",
    "    resident_clean['총_상주인구'] = resident_clean[resident_pop_cols[0]]\n",
    "else:\n",
    "    print(\"   ⚠️ 상주인구 컬럼 없음\")\n",
    "    resident_clean = None\n",
    "\n",
    "if resident_clean is not None:\n",
    "    resident_selected = resident_clean[['TRDAR_CD', '총_상주인구']].copy()\n",
    "    master_clean = master_clean.merge(resident_selected, on='TRDAR_CD', how='left')\n",
    "    print(f\"   📊 상주인구 매칭: {(master_clean['총_상주인구'].notna().sum() / len(master_clean)):.1%}\")\n",
    "\n",
    "# 5. 소득 데이터 조인\n",
    "print(f\"\\n5️⃣ 소득 데이터 조인:\")\n",
    "income_clean['TRDAR_CD'] = income_clean['상권_코드']\n",
    "\n",
    "income_cols = [col for col in income_clean.columns if '소득' in col]\n",
    "if income_cols:\n",
    "    income_clean['평균_소득'] = income_clean[income_cols[0]]\n",
    "    income_selected = income_clean[['TRDAR_CD', '평균_소득']].copy()\n",
    "    master_clean = master_clean.merge(income_selected, on='TRDAR_CD', how='left')\n",
    "    print(f\"   📊 소득 매칭: {(master_clean['평균_소득'].notna().sum() / len(master_clean)):.1%}\")\n",
    "\n",
    "print(f\"\\n🎯 깔끔한 마스터 데이터셋: {master_clean.shape}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 📊 곱창집 특화 파생지표 재계산\n",
    "# ================================================================================\n",
    "\n",
    "print(\"📊 곱창집 특화 파생지표 재계산\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 기본 효율성 지표\n",
    "print(\"1️⃣ 기본 효율성 지표:\")\n",
    "\n",
    "# 총 인구 (상주 + 유동)\n",
    "if '총_상주인구' in master_clean.columns:\n",
    "    master_clean['총_인구'] = (master_clean['총_유동인구_수'].fillna(0) + \n",
    "                              master_clean['총_상주인구'].fillna(0))\n",
    "else:\n",
    "    master_clean['총_인구'] = master_clean['총_유동인구_수'].fillna(0)\n",
    "\n",
    "# 매출 효율성\n",
    "if '총_매출' in master_clean.columns:\n",
    "    master_clean['인당_매출효율'] = master_clean['총_매출'] / master_clean['총_인구']\n",
    "    master_clean['야간_매출효율'] = master_clean['총_매출'] / master_clean['야간_유동인구_17_24']\n",
    "    \n",
    "    # 무한대 값 처리\n",
    "    master_clean['인당_매출효율'] = master_clean['인당_매출효율'].replace([np.inf, -np.inf], np.nan)\n",
    "    master_clean['야간_매출효율'] = master_clean['야간_매출효율'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    print(f\"   ✅ 인당 매출효율: 평균 {master_clean['인당_매출효율'].mean():.0f}원/명\")\n",
    "    print(f\"   ✅ 야간 매출효율: 평균 {master_clean['야간_매출효율'].mean():.0f}원/명\")\n",
    "\n",
    "# 2. 곱창집 특화 지표\n",
    "print(f\"\\n2️⃣ 곱창집 특화 지표:\")\n",
    "\n",
    "# 주류 친화 지수\n",
    "master_clean['주류친화_지수'] = (master_clean['야간_비율'].fillna(0) * 0.6 + \n",
    "                              (master_clean['주말_프리미엄'].fillna(1) - 1) * 0.4)\n",
    "\n",
    "# 타겟 연령대 비율 (20-40대)\n",
    "target_age_cols = ['연령대_20_유동인구_수', '연령대_30_유동인구_수', '연령대_40_유동인구_수']\n",
    "available_age_cols = [col for col in target_age_cols if col in master_clean.columns]\n",
    "\n",
    "if available_age_cols:\n",
    "    master_clean['타겟연령_비율'] = (master_clean[available_age_cols].sum(axis=1) / \n",
    "                                 master_clean['총_유동인구_수'])\n",
    "    master_clean['타겟연령_비율'] = master_clean['타겟연령_비율'].fillna(0)\n",
    "    print(f\"   ✅ 타겟연령(20-40대) 비율: 평균 {master_clean['타겟연령_비율'].mean():.1%}\")\n",
    "\n",
    "# 성비 균형도\n",
    "if all(col in master_clean.columns for col in ['남성_유동인구_수', '여성_유동인구_수']):\n",
    "    master_clean['성비_균형도'] = (1 - abs(master_clean['남성_유동인구_수'] - \n",
    "                                        master_clean['여성_유동인구_수']) / \n",
    "                                  master_clean['총_유동인구_수'])\n",
    "    master_clean['성비_균형도'] = master_clean['성비_균형도'].fillna(0.5)\n",
    "    print(f\"   ✅ 성비 균형도: 평균 {master_clean['성비_균형도'].mean():.1%}\")\n",
    "\n",
    "print(f\"   ✅ 주류친화 지수: 평균 {master_clean['주류친화_지수'].mean():.2f}\")\n",
    "\n",
    "# 3. 점수화 (1-5점)\n",
    "print(f\"\\n3️⃣ 점수화 (1-5점):\")\n",
    "\n",
    "scoring_cols = ['야간_유동인구_17_24', '총_매출', '주류친화_지수']\n",
    "available_scoring_cols = [col for col in scoring_cols if col in master_clean.columns]\n",
    "\n",
    "for col in available_scoring_cols:\n",
    "    score_col = f'{col}_점수'\n",
    "    try:\n",
    "        master_clean[score_col] = pd.qcut(master_clean[col].fillna(0), \n",
    "                                         q=5, labels=[1,2,3,4,5], \n",
    "                                         duplicates='drop').astype(float)\n",
    "        print(f\"   ✅ {col} → {score_col}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ {col} 점수화 실패: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🗺️ 지리정보 GeoDataFrame 생성\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🗺️ 지리정보 GeoDataFrame 생성\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if lng_col and lat_col:\n",
    "    try:\n",
    "        import geopandas as gpd\n",
    "        from shapely.geometry import Point\n",
    "        \n",
    "        # 유효한 좌표 데이터 필터링\n",
    "        valid_coords = (master_clean[lng_col].notna() & \n",
    "                       master_clean[lat_col].notna())\n",
    "        \n",
    "        geo_data = master_clean[valid_coords].copy()\n",
    "        \n",
    "        # Point 지오메트리 생성\n",
    "        geometry = [Point(lng, lat) for lng, lat in \n",
    "                   zip(geo_data[lng_col], geo_data[lat_col])]\n",
    "        \n",
    "        # GeoDataFrame 생성\n",
    "        master_gdf = gpd.GeoDataFrame(geo_data, geometry=geometry, crs='EPSG:4326')\n",
    "        \n",
    "        print(f\"   ✅ GeoDataFrame 생성: {len(master_gdf):,}개 상권\")\n",
    "        print(f\"   📐 좌표계: EPSG:4326 (WGS84)\")\n",
    "        print(f\"   📊 지리정보 비율: {len(master_gdf)/len(master_clean):.1%}\")\n",
    "        \n",
    "        # GPKG 저장\n",
    "        output_path = DATA_PATH / \"processed\"\n",
    "        output_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        gpkg_file = output_path / \"seoul_gopchang_master_clean.gpkg\"\n",
    "        master_gdf.to_file(gpkg_file, driver='GPKG')\n",
    "        print(f\"   💾 GeoPackage 저장: {gpkg_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ GeoDataFrame 생성 실패: {e}\")\n",
    "        master_gdf = None\n",
    "else:\n",
    "    print(f\"   ⚠️ 좌표 정보 부족 - GeoPackage 생성 불가\")\n",
    "    master_gdf = None\n",
    "\n",
    "# CSV 저장\n",
    "csv_file = DATA_PATH / \"processed\" / \"seoul_gopchang_master_clean.csv\"\n",
    "master_clean.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"   💾 CSV 저장: {csv_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 📊 정제 결과 검증 및 시각화\n",
    "# ================================================================================\n",
    "\n",
    "print(\"📊 정제 결과 검증 및 시각화\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 기본 통계\n",
    "print(\"1️⃣ 정제 후 기본 통계:\")\n",
    "print(f\"   📊 총 상권 수: {len(master_clean):,}개\")\n",
    "print(f\"   📋 총 컬럼 수: {len(master_clean.columns)}개\")\n",
    "print(f\"   🌙 야간 데이터: {master_clean['야간_유동인구_17_24'].notna().sum():,}개\")\n",
    "print(f\"   💰 매출 데이터: {master_clean['총_매출'].notna().sum():,}개\")\n",
    "print(f\"   🗺️ 좌표 데이터: {len(master_gdf) if master_gdf is not None else 0:,}개\")\n",
    "\n",
    "# 2. 야간 유동인구 TOP 10 (정제 후)\n",
    "print(f\"\\n2️⃣ 야간 유동인구 TOP 10 (정제 후):\")\n",
    "if '야간_유동인구_17_24' in master_clean.columns and '상권_코드_명' in master_clean.columns:\n",
    "    top_clean = master_clean.nlargest(10, '야간_유동인구_17_24')[\n",
    "        ['상권_코드_명', '야간_유동인구_17_24', '총_매출']\n",
    "    ]\n",
    "    for i, (idx, row) in enumerate(top_clean.iterrows(), 1):\n",
    "        sales_info = f\"{row['총_매출']/1e8:.1f}억원\" if pd.notna(row['총_매출']) else \"N/A\"\n",
    "        print(f\"   {i:2d}. {row['상권_코드_명']:20s}: {row['야간_유동인구_17_24']:7,.0f}명 ({sales_info})\")\n",
    "\n",
    "# 3. 데이터 품질 비교 (정제 전후)\n",
    "print(f\"\\n3️⃣ 데이터 품질 비교:\")\n",
    "print(f\"   📊 정제 전: 471,240개 → 정제 후: {len(master_clean):,}개\")\n",
    "print(f\"   📉 데이터 크기 감소: {(1 - len(master_clean)/471240)*100:.1f}%\")\n",
    "print(f\"   ✅ 정상 상권 수 달성: {len(master_clean) == 1650}\")\n",
    "\n",
    "# 4. 시각화\n",
    "fig_summary = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('정제 전후 비교', '야간 유동인구 분포', '매출 효율성', '데이터 완성도'),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"histogram\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# 4-1. 정제 전후 비교\n",
    "fig_summary.add_trace(\n",
    "    go.Bar(x=['정제 전', '정제 후'], y=[471240, len(master_clean)],\n",
    "           marker_color=['lightcoral', 'lightgreen'],\n",
    "           text=['471K개', f'{len(master_clean):,}개'],\n",
    "           textposition='outside'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 4-2. 야간 유동인구 분포\n",
    "if '야간_유동인구_17_24' in master_clean.columns:\n",
    "    night_data = master_clean['야간_유동인구_17_24'].dropna()\n",
    "    fig_summary.add_trace(\n",
    "        go.Histogram(x=night_data, nbinsx=30, marker_color='lightblue'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# 4-3. 매출 효율성 (야간 인구 vs 매출)\n",
    "if all(col in master_clean.columns for col in ['야간_유동인구_17_24', '총_매출']):\n",
    "    clean_data = master_clean[['야간_유동인구_17_24', '총_매출']].dropna()\n",
    "    if len(clean_data) > 0:\n",
    "        fig_summary.add_trace(\n",
    "            go.Scatter(x=clean_data['야간_유동인구_17_24'], \n",
    "                      y=clean_data['총_매출'],\n",
    "                      mode='markers', marker_color='orange', opacity=0.6),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "# 4-4. 데이터 완성도\n",
    "completeness = {}\n",
    "key_cols = ['총_유동인구_수', '야간_유동인구_17_24', '총_매출', '총_상주인구']\n",
    "for col in key_cols:\n",
    "    if col in master_clean.columns:\n",
    "        completeness[col] = (master_clean[col].notna().sum() / len(master_clean)) * 100\n",
    "\n",
    "if completeness:\n",
    "    fig_summary.add_trace(\n",
    "        go.Bar(x=list(completeness.keys()), y=list(completeness.values()),\n",
    "               marker_color='lightgreen',\n",
    "               text=[f'{v:.1f}%' for v in completeness.values()],\n",
    "               textposition='outside'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "fig_summary.update_layout(\n",
    "    title=\"🧹 데이터 정제 결과 요약\",\n",
    "    height=800,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig_summary.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🎯 완료 및 다음 단계\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🎯 데이터 정제 완료!\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(f\"✅ 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\n📊 최종 정제 결과:\")\n",
    "print(f\"   🗃️  깔끔한 마스터 데이터: {master_clean.shape}\")\n",
    "print(f\"   🌙 야간 유동인구: {master_clean['야간_유동인구_17_24'].notna().sum():,}개 상권\")\n",
    "print(f\"   💰 매출 데이터: {master_clean['총_매출'].notna().sum():,}개 상권\")\n",
    "print(f\"   🗺️ 지리정보: {len(master_gdf) if master_gdf is not None else 0:,}개 상권\")\n",
    "print(f\"   💾 저장 파일: seoul_gopchang_master_clean.csv / .gpkg\")\n",
    "\n",
    "print(f\"\\n🎯 해결된 문제들:\")\n",
    "print(f\"   ✅ 업종별 중복 제거: 471K → {len(master_clean):,}개\")\n",
    "print(f\"   ✅ 정확한 상권 수: {len(master_clean) == 1650}\")\n",
    "print(f\"   ✅ 좌표 정보 복구: {len(master_gdf) if master_gdf is not None else 0}개 상권\")\n",
    "print(f\"   ✅ 올바른 TOP 상권 확인\")\n",
    "\n",
    "print(f\"\\n🚀 이제 준비된 다음 단계:\")\n",
    "print(f\"   A. KPI 스코어링 (경쟁밀도, 통합점수) ⭐ 추천\")\n",
    "print(f\"   B. 지도 시각화 (Folium + 좌표)\")\n",
    "print(f\"   C. 상권별 상세 분석 (TOP 30)\")\n",
    "print(f\"   D. 실시간 대시보드\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🧹 데이터 정제 완료!\")\n",
    "print(\"🎯 이제 깔끔한 데이터로 본격적인 분석을 시작할 수 있습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
