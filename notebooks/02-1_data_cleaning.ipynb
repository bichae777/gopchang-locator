{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§¹ ê³±ì°½ì§‘ ì…ì§€ ë¶„ì„ ë°ì´í„° ì •ì œ\n",
    "# 02-1_data_cleaning.ipynb\n",
    "# \n",
    "# ëª©ì : ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ì˜ í’ˆì§ˆ ë¬¸ì œ í•´ê²°\n",
    "#       - ì—…ì¢…ë³„ ì¤‘ë³µ ì œê±° (471K â†’ 1.6K)\n",
    "#       - ì¢Œí‘œ ì •ë³´ ë³µêµ¬\n",
    "#       - ì •í™•í•œ ìƒê¶Œë³„ ì§‘ê³„\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "# ================================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ì„¤ì •\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"ğŸ§¹ ê³±ì°½ì§‘ ì…ì§€ ë¶„ì„ ë°ì´í„° ì •ì œ ì‹œì‘!\")\n",
    "print(f\"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ“‚ ì›ë³¸ ë°ì´í„° ë‹¤ì‹œ ë¡œë“œ (ì •ì œìš©)\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ“‚ ì›ë³¸ ë°ì´í„° ë‹¤ì‹œ ë¡œë“œ (ì •ì œìš©)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "DATA_PATH = Path(\"../data\")\n",
    "RAW_PATH = DATA_PATH / \"raw\"\n",
    "\n",
    "# 1. ê¸°ì¤€ ë°ì´í„°: ìƒê¶Œ ê²½ê³„ (1,650ê°œ ìƒê¶Œ)\n",
    "boundary_df = pd.read_csv(DATA_PATH / \"boundary/boundary_all.csv\", encoding='utf-8')\n",
    "print(f\"ğŸ“ ìƒê¶Œ ê²½ê³„: {boundary_df.shape} (ê¸°ì¤€)\")\n",
    "\n",
    "# 2. ìµœì‹  ë¶„ê¸° ë°ì´í„°ë“¤ ë¡œë“œ\n",
    "flow_df = pd.read_csv(RAW_PATH / \"flow/flow_all.csv\", encoding='utf-8')\n",
    "latest_quarter = flow_df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].max()\n",
    "flow_latest = flow_df[flow_df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'] == latest_quarter].copy()\n",
    "print(f\"ğŸ‘¥ ìœ ë™ì¸êµ¬ ({latest_quarter}): {flow_latest.shape}\")\n",
    "\n",
    "# 3. ë§¤ì¶œ ë°ì´í„° (ë¬¸ì œì˜ í•µì‹¬)\n",
    "sales_df = pd.read_csv(RAW_PATH / \"sales/sales_all.csv\", encoding='utf-8')\n",
    "sales_latest = sales_df[sales_df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'] == latest_quarter].copy()\n",
    "print(f\"ğŸ’° ë§¤ì¶œ ì›ë³¸ ({latest_quarter}): {sales_latest.shape} â† ë¬¸ì œ!\")\n",
    "\n",
    "# 4. ìƒì£¼ì¸êµ¬\n",
    "resident_df = pd.read_csv(RAW_PATH / \"resident/resident_all.csv\", encoding='utf-8')\n",
    "print(f\"ğŸ  ìƒì£¼ì¸êµ¬: {resident_df.shape}\")\n",
    "\n",
    "# 5. ì†Œë“Â·ì†Œë¹„\n",
    "income_df = pd.read_csv(RAW_PATH / \"income_exp/income_all.csv\", encoding='utf-8')\n",
    "income_latest = income_df[income_df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'] == latest_quarter].copy()\n",
    "print(f\"ğŸ’³ ì†Œë“Â·ì†Œë¹„ ({latest_quarter}): {income_latest.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ” ë¬¸ì œ ì§„ë‹¨: ì¤‘ë³µ ë°ì´í„° ë¶„ì„\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ” ë¬¸ì œ ì§„ë‹¨: ì¤‘ë³µ ë°ì´í„° ë¶„ì„\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. ë§¤ì¶œ ë°ì´í„° ì¤‘ë³µ ì›ì¸ ë¶„ì„\n",
    "print(\"1ï¸âƒ£ ë§¤ì¶œ ë°ì´í„° êµ¬ì¡° ë¶„ì„:\")\n",
    "print(f\"   ğŸ“Š ì´ í–‰ìˆ˜: {len(sales_latest):,}ê°œ\")\n",
    "print(f\"   ğŸª ê³ ìœ  ìƒê¶Œìˆ˜: {sales_latest['ìƒê¶Œ_ì½”ë“œ'].nunique():,}ê°œ\")\n",
    "\n",
    "# ì—…ì¢…ë³„ ë¶„ì„\n",
    "if 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…' in sales_latest.columns:\n",
    "    service_counts = sales_latest['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'].value_counts()\n",
    "    print(f\"   ğŸ·ï¸ ì—…ì¢… ì¢…ë¥˜: {len(service_counts)}ê°œ\")\n",
    "    print(f\"   ğŸ“‹ ì£¼ìš” ì—…ì¢…:\")\n",
    "    for i, (service, count) in enumerate(service_counts.head(5).items()):\n",
    "        print(f\"      {i+1}. {service}: {count:,}ê°œ\")\n",
    "\n",
    "# ìƒê¶Œë³„ í–‰ìˆ˜ ë¶„ì„\n",
    "district_counts = sales_latest['ìƒê¶Œ_ì½”ë“œ'].value_counts()\n",
    "print(f\"\\n   ğŸ“Š ìƒê¶Œë³„ í‰ê·  í–‰ìˆ˜: {district_counts.mean():.1f}ê°œ\")\n",
    "print(f\"   ğŸ“Š ìƒê¶Œë³„ ìµœëŒ€ í–‰ìˆ˜: {district_counts.max()}ê°œ\")\n",
    "\n",
    "# 2. ê¸°íƒ€ ë°ì´í„° ì¤‘ë³µ í™•ì¸\n",
    "print(f\"\\n2ï¸âƒ£ ê¸°íƒ€ ë°ì´í„° ì¤‘ë³µ í™•ì¸:\")\n",
    "datasets = {\n",
    "    'boundary': boundary_df,\n",
    "    'flow_latest': flow_latest,\n",
    "    'resident': resident_df,\n",
    "    'income_latest': income_latest\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    if 'ìƒê¶Œ_ì½”ë“œ' in df.columns:\n",
    "        unique_districts = df['ìƒê¶Œ_ì½”ë“œ'].nunique()\n",
    "        total_rows = len(df)\n",
    "        print(f\"   {name:12s}: {total_rows:5,}í–‰ / {unique_districts:4,}ê°œ ìƒê¶Œ = {total_rows/unique_districts if unique_districts > 0 else 0:4.1f}í–‰/ìƒê¶Œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ”§ ë°ì´í„° ì •ì œ 1ë‹¨ê³„: ì—…ì¢…ë³„ ì§‘ê³„\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ”§ ë°ì´í„° ì •ì œ 1ë‹¨ê³„: ì—…ì¢…ë³„ ì§‘ê³„\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. ë§¤ì¶œ ë°ì´í„° ìƒê¶Œë³„ ì§‘ê³„\n",
    "print(\"1ï¸âƒ£ ë§¤ì¶œ ë°ì´í„° ìƒê¶Œë³„ ì§‘ê³„:\")\n",
    "\n",
    "# ë§¤ì¶œ ê´€ë ¨ ì»¬ëŸ¼ ì‹ë³„\n",
    "sales_amount_cols = [col for col in sales_latest.columns if 'ë§¤ì¶œ_ê¸ˆì•¡' in col]\n",
    "sales_count_cols = [col for col in sales_latest.columns if 'ë§¤ì¶œ_ê±´ìˆ˜' in col]\n",
    "\n",
    "print(f\"   ğŸ“‹ ë§¤ì¶œê¸ˆì•¡ ì»¬ëŸ¼: {len(sales_amount_cols)}ê°œ\")\n",
    "print(f\"   ğŸ“‹ ë§¤ì¶œê±´ìˆ˜ ì»¬ëŸ¼: {len(sales_count_cols)}ê°œ\")\n",
    "\n",
    "# ìƒê¶Œë³„ ì§‘ê³„ (ì—…ì¢…ë³„ í•©ê³„)\n",
    "sales_agg_dict = {}\n",
    "\n",
    "# ë§¤ì¶œê¸ˆì•¡ í•©ê³„\n",
    "for col in sales_amount_cols:\n",
    "    sales_agg_dict[col] = 'sum'\n",
    "\n",
    "# ë§¤ì¶œê±´ìˆ˜ í•©ê³„  \n",
    "for col in sales_count_cols:\n",
    "    sales_agg_dict[col] = 'sum'\n",
    "\n",
    "# ê¸°ë³¸ ì •ë³´ëŠ” ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©\n",
    "basic_cols = ['ìƒê¶Œ_êµ¬ë¶„_ì½”ë“œ', 'ìƒê¶Œ_êµ¬ë¶„_ì½”ë“œ_ëª…', 'ìƒê¶Œ_ì½”ë“œ_ëª…']\n",
    "for col in basic_cols:\n",
    "    if col in sales_latest.columns:\n",
    "        sales_agg_dict[col] = 'first'\n",
    "\n",
    "# ì§‘ê³„ ì‹¤í–‰\n",
    "sales_clean = sales_latest.groupby('ìƒê¶Œ_ì½”ë“œ').agg(sales_agg_dict).reset_index()\n",
    "\n",
    "print(f\"   ğŸ“Š ì§‘ê³„ ì „: {len(sales_latest):,}í–‰\")\n",
    "print(f\"   ğŸ“Š ì§‘ê³„ í›„: {len(sales_clean):,}í–‰\")\n",
    "print(f\"   âœ… ìƒê¶Œ ìˆ˜ ì¼ì¹˜: {len(sales_clean) == sales_latest['ìƒê¶Œ_ì½”ë“œ'].nunique()}\")\n",
    "\n",
    "# 2. ê¸°íƒ€ ë°ì´í„°ë„ ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ)\n",
    "print(f\"\\n2ï¸âƒ£ ê¸°íƒ€ ë°ì´í„° ì¤‘ë³µ ì œê±°:\")\n",
    "\n",
    "# ìœ ë™ì¸êµ¬ (ì´ë¯¸ ê¹¨ë—í•´ì•¼ í•˜ì§€ë§Œ í™•ì¸)\n",
    "flow_clean = flow_latest.drop_duplicates(subset=['ìƒê¶Œ_ì½”ë“œ']).copy()\n",
    "print(f\"   ğŸ‘¥ ìœ ë™ì¸êµ¬: {len(flow_latest):,} â†’ {len(flow_clean):,}ê°œ\")\n",
    "\n",
    "# ìƒì£¼ì¸êµ¬ - ìƒê¶Œë³„ ì§‘ê³„ (ì—°ë ¹ëŒ€ë³„ í•©ê³„)\n",
    "resident_pop_cols = [col for col in resident_df.columns if 'ìƒì£¼ì¸êµ¬_ìˆ˜' in col]\n",
    "if not resident_pop_cols:\n",
    "    resident_pop_cols = [col for col in resident_df.columns if 'ì¸êµ¬_ìˆ˜' in col]\n",
    "\n",
    "if resident_pop_cols:\n",
    "    resident_agg = {}\n",
    "    for col in resident_pop_cols:\n",
    "        resident_agg[col] = 'sum'\n",
    "    \n",
    "    # market_code ê¸°ì¤€ ì§‘ê³„\n",
    "    if 'market_code' in resident_df.columns:\n",
    "        resident_clean = resident_df.groupby('market_code').agg(resident_agg).reset_index()\n",
    "        resident_clean['ìƒê¶Œ_ì½”ë“œ'] = resident_clean['market_code']  # ì»¬ëŸ¼ëª… í†µì¼\n",
    "    else:\n",
    "        resident_clean = resident_df.copy()\n",
    "        \n",
    "    print(f\"   ğŸ  ìƒì£¼ì¸êµ¬: {len(resident_df):,} â†’ {len(resident_clean):,}ê°œ\")\n",
    "else:\n",
    "    resident_clean = resident_df.copy()\n",
    "    print(f\"   ğŸ  ìƒì£¼ì¸êµ¬: ì§‘ê³„ ì»¬ëŸ¼ ì—†ìŒ ({len(resident_clean):,}ê°œ ìœ ì§€)\")\n",
    "\n",
    "# ì†Œë“Â·ì†Œë¹„ ì¤‘ë³µ ì œê±°\n",
    "income_clean = income_latest.drop_duplicates(subset=['ìƒê¶Œ_ì½”ë“œ']).copy()\n",
    "print(f\"   ğŸ’³ ì†Œë“Â·ì†Œë¹„: {len(income_latest):,} â†’ {len(income_clean):,}ê°œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ—ºï¸ ë°ì´í„° ì •ì œ 2ë‹¨ê³„: ì¢Œí‘œ ì •ë³´ ë³µêµ¬\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ—ºï¸ ë°ì´í„° ì •ì œ 2ë‹¨ê³„: ì¢Œí‘œ ì •ë³´ ë³µêµ¬\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. ì¢Œí‘œ ì»¬ëŸ¼ ì¬íƒì§€\n",
    "print(\"1ï¸âƒ£ ì¢Œí‘œ ì»¬ëŸ¼ ì¬íƒì§€:\")\n",
    "coord_columns = [col for col in boundary_df.columns if any(keyword in col.lower() \n",
    "                for keyword in ['x', 'y', 'ê²½ë„', 'ìœ„ë„', 'lng', 'lat', 'ì¢Œí‘œ'])]\n",
    "\n",
    "print(f\"   ğŸ“ ì¢Œí‘œ ê´€ë ¨ ì»¬ëŸ¼: {coord_columns}\")\n",
    "\n",
    "# ì¢Œí‘œ ë°ì´í„° í™•ì¸\n",
    "for col in coord_columns:\n",
    "    sample_values = boundary_df[col].dropna().head(5).tolist()\n",
    "    print(f\"      {col}: {sample_values}\")\n",
    "\n",
    "# 2. ê²½ë„/ìœ„ë„ ì‹ë³„\n",
    "lng_col = None\n",
    "lat_col = None\n",
    "\n",
    "# ê²½ë„ (Xì¢Œí‘œ, ë™ê²½)\n",
    "for col in coord_columns:\n",
    "    if any(keyword in col.lower() for keyword in ['x', 'ê²½ë„', 'lng', 'lon']):\n",
    "        lng_col = col\n",
    "        break\n",
    "\n",
    "# ìœ„ë„ (Yì¢Œí‘œ, ë¶ìœ„)  \n",
    "for col in coord_columns:\n",
    "    if any(keyword in col.lower() for keyword in ['y', 'ìœ„ë„', 'lat']):\n",
    "        lat_col = col\n",
    "        break\n",
    "\n",
    "if lng_col and lat_col:\n",
    "    print(f\"\\n   âœ… ê²½ë„ ì»¬ëŸ¼: {lng_col}\")\n",
    "    print(f\"   âœ… ìœ„ë„ ì»¬ëŸ¼: {lat_col}\")\n",
    "    \n",
    "    # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì¦\n",
    "    valid_lng = boundary_df[lng_col].notna()\n",
    "    valid_lat = boundary_df[lat_col].notna()\n",
    "    valid_coords = valid_lng & valid_lat\n",
    "    \n",
    "    print(f\"   ğŸ“Š ìœ íš¨í•œ ê²½ë„: {valid_lng.sum():,}ê°œ\")\n",
    "    print(f\"   ğŸ“Š ìœ íš¨í•œ ìœ„ë„: {valid_lat.sum():,}ê°œ\") \n",
    "    print(f\"   ğŸ“Š ì™„ì „í•œ ì¢Œí‘œ: {valid_coords.sum():,}ê°œ\")\n",
    "    \n",
    "    # ì¢Œí‘œ ë²”ìœ„ ê²€ì¦ (ì„œìš¸ ì§€ì—­)\n",
    "    if valid_coords.sum() > 0:\n",
    "        lng_range = [boundary_df.loc[valid_coords, lng_col].min(), \n",
    "                     boundary_df.loc[valid_coords, lng_col].max()]\n",
    "        lat_range = [boundary_df.loc[valid_coords, lat_col].min(), \n",
    "                     boundary_df.loc[valid_coords, lat_col].max()]\n",
    "        \n",
    "        print(f\"   ğŸ“ ê²½ë„ ë²”ìœ„: {lng_range[0]:.6f} ~ {lng_range[1]:.6f}\")\n",
    "        print(f\"   ğŸ“ ìœ„ë„ ë²”ìœ„: {lat_range[0]:.6f} ~ {lat_range[1]:.6f}\")\n",
    "        \n",
    "        # ì„œìš¸ ì¢Œí‘œ ë²”ìœ„ ê²€ì¦ (ëŒ€ëµì )\n",
    "        seoul_lng_range = [126.7, 127.3]  # ì„œìš¸ ê²½ë„ ë²”ìœ„\n",
    "        seoul_lat_range = [37.4, 37.7]    # ì„œìš¸ ìœ„ë„ ë²”ìœ„\n",
    "        \n",
    "        lng_valid = (lng_range[0] >= seoul_lng_range[0] and lng_range[1] <= seoul_lng_range[1])\n",
    "        lat_valid = (lat_range[0] >= seoul_lat_range[0] and lat_range[1] <= seoul_lat_range[1])\n",
    "        \n",
    "        if lng_valid and lat_valid:\n",
    "            print(f\"   âœ… ì„œìš¸ ì§€ì—­ ì¢Œí‘œ ë²”ìœ„ ì í•©\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ ì¢Œí‘œ ë²”ìœ„ í™•ì¸ í•„ìš” (ì„œìš¸ ì§€ì—­ ë²—ì–´ë‚¨)\")\n",
    "else:\n",
    "    print(f\"   âŒ ê²½ë„/ìœ„ë„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ”— ë°ì´í„° ì •ì œ 3ë‹¨ê³„: ê¹”ë”í•œ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ì¬êµ¬ì¶•\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ”— ë°ì´í„° ì •ì œ 3ë‹¨ê³„: ê¹”ë”í•œ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ì¬êµ¬ì¶•\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. ê¸°ì¤€ ë°ì´í„°: ìƒê¶Œ ê²½ê³„ (ì¢Œí‘œ í¬í•¨)\n",
    "print(\"1ï¸âƒ£ ê¸°ì¤€ ë°ì´í„° ì„¤ì •:\")\n",
    "master_clean = boundary_df.copy()\n",
    "\n",
    "# ìƒê¶Œì½”ë“œ ì»¬ëŸ¼ í†µì¼\n",
    "if 'ìƒê¶Œ_ì½”ë“œ' in master_clean.columns:\n",
    "    master_clean['TRDAR_CD'] = master_clean['ìƒê¶Œ_ì½”ë“œ']\n",
    "else:\n",
    "    print(\"   âŒ ìƒê¶Œ_ì½”ë“œ ì»¬ëŸ¼ ì—†ìŒ!\")\n",
    "\n",
    "print(f\"   ğŸ“ ê¸°ì¤€ ìƒê¶Œ: {len(master_clean):,}ê°œ\")\n",
    "\n",
    "# 2. ìœ ë™ì¸êµ¬ ì¡°ì¸ (17-24ì‹œ ì•¼ê°„ ê³„ì‚° í¬í•¨)\n",
    "print(f\"\\n2ï¸âƒ£ ìœ ë™ì¸êµ¬ ë°ì´í„° ì¡°ì¸:\")\n",
    "\n",
    "# ì•¼ê°„ ìœ ë™ì¸êµ¬ ì¬ê³„ì‚°\n",
    "def calculate_night_flow_clean(df):\n",
    "    \"\"\"17-24ì‹œ ì•¼ê°„ ìœ ë™ì¸êµ¬ ê³„ì‚° (ê¹”ë”í•œ ë²„ì „)\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ì•¼ê°„ ìœ ë™ì¸êµ¬ (17-24ì‹œ)\n",
    "    df['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24'] = (df['ì‹œê°„ëŒ€_17_21_ìœ ë™ì¸êµ¬_ìˆ˜'] + \n",
    "                               df['ì‹œê°„ëŒ€_21_24_ìœ ë™ì¸êµ¬_ìˆ˜'])\n",
    "    \n",
    "    # ì•¼ê°„ ë¹„ìœ¨\n",
    "    df['ì•¼ê°„_ë¹„ìœ¨'] = df['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24'] / df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜']\n",
    "    \n",
    "    # ì£¼ë§ vs ì£¼ì¤‘\n",
    "    df['ì£¼ë§_í‰ê· '] = (df['í† ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜'] + df['ì¼ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜']) / 2\n",
    "    df['ì£¼ì¤‘_í‰ê· '] = (df['ì›”ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜'] + df['í™”ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜'] + \n",
    "                     df['ìˆ˜ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜'] + df['ëª©ìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜'] + \n",
    "                     df['ê¸ˆìš”ì¼_ìœ ë™ì¸êµ¬_ìˆ˜']) / 5\n",
    "    df['ì£¼ë§_í”„ë¦¬ë¯¸ì—„'] = df['ì£¼ë§_í‰ê· '] / df['ì£¼ì¤‘_í‰ê· ']\n",
    "    \n",
    "    return df\n",
    "\n",
    "flow_clean = calculate_night_flow_clean(flow_clean)\n",
    "\n",
    "# ìƒê¶Œì½”ë“œ í†µì¼ í›„ ì¡°ì¸\n",
    "flow_clean['TRDAR_CD'] = flow_clean['ìƒê¶Œ_ì½”ë“œ']\n",
    "\n",
    "# í•µì‹¬ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "flow_key_cols = ['TRDAR_CD', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24', 'ì•¼ê°„_ë¹„ìœ¨',\n",
    "                 'ì£¼ë§_í‰ê· ', 'ì£¼ì¤‘_í‰ê· ', 'ì£¼ë§_í”„ë¦¬ë¯¸ì—„',\n",
    "                 'ë‚¨ì„±_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—¬ì„±_ìœ ë™ì¸êµ¬_ìˆ˜',\n",
    "                 'ì—°ë ¹ëŒ€_20_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_30_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_40_ìœ ë™ì¸êµ¬_ìˆ˜']\n",
    "\n",
    "available_flow_cols = [col for col in flow_key_cols if col in flow_clean.columns]\n",
    "flow_selected = flow_clean[available_flow_cols].copy()\n",
    "\n",
    "master_clean = master_clean.merge(flow_selected, on='TRDAR_CD', how='left')\n",
    "print(f\"   ğŸ“Š ìœ ë™ì¸êµ¬ ë§¤ì¹­: {(master_clean['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'].notna().sum() / len(master_clean)):.1%}\")\n",
    "\n",
    "# 3. ë§¤ì¶œ ë°ì´í„° ì¡°ì¸ (ì§‘ê³„ëœ ê¹”ë”í•œ ë°ì´í„°)\n",
    "print(f\"\\n3ï¸âƒ£ ë§¤ì¶œ ë°ì´í„° ì¡°ì¸:\")\n",
    "sales_clean['TRDAR_CD'] = sales_clean['ìƒê¶Œ_ì½”ë“œ']\n",
    "\n",
    "# ì£¼ìš” ë§¤ì¶œ ì»¬ëŸ¼ ì„ íƒ\n",
    "main_sales_col = 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡' if 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡' in sales_clean.columns else sales_amount_cols[0]\n",
    "sales_clean['ì´_ë§¤ì¶œ'] = sales_clean[main_sales_col]\n",
    "\n",
    "sales_selected = sales_clean[['TRDAR_CD', 'ì´_ë§¤ì¶œ']].copy()\n",
    "master_clean = master_clean.merge(sales_selected, on='TRDAR_CD', how='left')\n",
    "print(f\"   ğŸ“Š ë§¤ì¶œ ë§¤ì¹­: {(master_clean['ì´_ë§¤ì¶œ'].notna().sum() / len(master_clean)):.1%}\")\n",
    "\n",
    "# 4. ìƒì£¼ì¸êµ¬ ì¡°ì¸\n",
    "print(f\"\\n4ï¸âƒ£ ìƒì£¼ì¸êµ¬ ì¡°ì¸:\")\n",
    "if 'market_code' in resident_clean.columns:\n",
    "    resident_clean['TRDAR_CD'] = resident_clean['market_code']\n",
    "elif 'ìƒê¶Œ_ì½”ë“œ' in resident_clean.columns:\n",
    "    resident_clean['TRDAR_CD'] = resident_clean['ìƒê¶Œ_ì½”ë“œ']\n",
    "\n",
    "# ì´ ìƒì£¼ì¸êµ¬ ê³„ì‚°\n",
    "resident_pop_cols = [col for col in resident_clean.columns if 'ì¸êµ¬_ìˆ˜' in col]\n",
    "if len(resident_pop_cols) > 1:\n",
    "    resident_clean['ì´_ìƒì£¼ì¸êµ¬'] = resident_clean[resident_pop_cols].sum(axis=1)\n",
    "elif len(resident_pop_cols) == 1:\n",
    "    resident_clean['ì´_ìƒì£¼ì¸êµ¬'] = resident_clean[resident_pop_cols[0]]\n",
    "else:\n",
    "    print(\"   âš ï¸ ìƒì£¼ì¸êµ¬ ì»¬ëŸ¼ ì—†ìŒ\")\n",
    "    resident_clean = None\n",
    "\n",
    "if resident_clean is not None:\n",
    "    resident_selected = resident_clean[['TRDAR_CD', 'ì´_ìƒì£¼ì¸êµ¬']].copy()\n",
    "    master_clean = master_clean.merge(resident_selected, on='TRDAR_CD', how='left')\n",
    "    print(f\"   ğŸ“Š ìƒì£¼ì¸êµ¬ ë§¤ì¹­: {(master_clean['ì´_ìƒì£¼ì¸êµ¬'].notna().sum() / len(master_clean)):.1%}\")\n",
    "\n",
    "# 5. ì†Œë“ ë°ì´í„° ì¡°ì¸\n",
    "print(f\"\\n5ï¸âƒ£ ì†Œë“ ë°ì´í„° ì¡°ì¸:\")\n",
    "income_clean['TRDAR_CD'] = income_clean['ìƒê¶Œ_ì½”ë“œ']\n",
    "\n",
    "income_cols = [col for col in income_clean.columns if 'ì†Œë“' in col]\n",
    "if income_cols:\n",
    "    income_clean['í‰ê· _ì†Œë“'] = income_clean[income_cols[0]]\n",
    "    income_selected = income_clean[['TRDAR_CD', 'í‰ê· _ì†Œë“']].copy()\n",
    "    master_clean = master_clean.merge(income_selected, on='TRDAR_CD', how='left')\n",
    "    print(f\"   ğŸ“Š ì†Œë“ ë§¤ì¹­: {(master_clean['í‰ê· _ì†Œë“'].notna().sum() / len(master_clean)):.1%}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ê¹”ë”í•œ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹: {master_clean.shape}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ“Š ê³±ì°½ì§‘ íŠ¹í™” íŒŒìƒì§€í‘œ ì¬ê³„ì‚°\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ“Š ê³±ì°½ì§‘ íŠ¹í™” íŒŒìƒì§€í‘œ ì¬ê³„ì‚°\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. ê¸°ë³¸ íš¨ìœ¨ì„± ì§€í‘œ\n",
    "print(\"1ï¸âƒ£ ê¸°ë³¸ íš¨ìœ¨ì„± ì§€í‘œ:\")\n",
    "\n",
    "# ì´ ì¸êµ¬ (ìƒì£¼ + ìœ ë™)\n",
    "if 'ì´_ìƒì£¼ì¸êµ¬' in master_clean.columns:\n",
    "    master_clean['ì´_ì¸êµ¬'] = (master_clean['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'].fillna(0) + \n",
    "                              master_clean['ì´_ìƒì£¼ì¸êµ¬'].fillna(0))\n",
    "else:\n",
    "    master_clean['ì´_ì¸êµ¬'] = master_clean['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'].fillna(0)\n",
    "\n",
    "# ë§¤ì¶œ íš¨ìœ¨ì„±\n",
    "if 'ì´_ë§¤ì¶œ' in master_clean.columns:\n",
    "    master_clean['ì¸ë‹¹_ë§¤ì¶œíš¨ìœ¨'] = master_clean['ì´_ë§¤ì¶œ'] / master_clean['ì´_ì¸êµ¬']\n",
    "    master_clean['ì•¼ê°„_ë§¤ì¶œíš¨ìœ¨'] = master_clean['ì´_ë§¤ì¶œ'] / master_clean['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24']\n",
    "    \n",
    "    # ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬\n",
    "    master_clean['ì¸ë‹¹_ë§¤ì¶œíš¨ìœ¨'] = master_clean['ì¸ë‹¹_ë§¤ì¶œíš¨ìœ¨'].replace([np.inf, -np.inf], np.nan)\n",
    "    master_clean['ì•¼ê°„_ë§¤ì¶œíš¨ìœ¨'] = master_clean['ì•¼ê°„_ë§¤ì¶œíš¨ìœ¨'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    print(f\"   âœ… ì¸ë‹¹ ë§¤ì¶œíš¨ìœ¨: í‰ê·  {master_clean['ì¸ë‹¹_ë§¤ì¶œíš¨ìœ¨'].mean():.0f}ì›/ëª…\")\n",
    "    print(f\"   âœ… ì•¼ê°„ ë§¤ì¶œíš¨ìœ¨: í‰ê·  {master_clean['ì•¼ê°„_ë§¤ì¶œíš¨ìœ¨'].mean():.0f}ì›/ëª…\")\n",
    "\n",
    "# 2. ê³±ì°½ì§‘ íŠ¹í™” ì§€í‘œ\n",
    "print(f\"\\n2ï¸âƒ£ ê³±ì°½ì§‘ íŠ¹í™” ì§€í‘œ:\")\n",
    "\n",
    "# ì£¼ë¥˜ ì¹œí™” ì§€ìˆ˜\n",
    "master_clean['ì£¼ë¥˜ì¹œí™”_ì§€ìˆ˜'] = (master_clean['ì•¼ê°„_ë¹„ìœ¨'].fillna(0) * 0.6 + \n",
    "                              (master_clean['ì£¼ë§_í”„ë¦¬ë¯¸ì—„'].fillna(1) - 1) * 0.4)\n",
    "\n",
    "# íƒ€ê²Ÿ ì—°ë ¹ëŒ€ ë¹„ìœ¨ (20-40ëŒ€)\n",
    "target_age_cols = ['ì—°ë ¹ëŒ€_20_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_30_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_40_ìœ ë™ì¸êµ¬_ìˆ˜']\n",
    "available_age_cols = [col for col in target_age_cols if col in master_clean.columns]\n",
    "\n",
    "if available_age_cols:\n",
    "    master_clean['íƒ€ê²Ÿì—°ë ¹_ë¹„ìœ¨'] = (master_clean[available_age_cols].sum(axis=1) / \n",
    "                                 master_clean['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'])\n",
    "    master_clean['íƒ€ê²Ÿì—°ë ¹_ë¹„ìœ¨'] = master_clean['íƒ€ê²Ÿì—°ë ¹_ë¹„ìœ¨'].fillna(0)\n",
    "    print(f\"   âœ… íƒ€ê²Ÿì—°ë ¹(20-40ëŒ€) ë¹„ìœ¨: í‰ê·  {master_clean['íƒ€ê²Ÿì—°ë ¹_ë¹„ìœ¨'].mean():.1%}\")\n",
    "\n",
    "# ì„±ë¹„ ê· í˜•ë„\n",
    "if all(col in master_clean.columns for col in ['ë‚¨ì„±_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—¬ì„±_ìœ ë™ì¸êµ¬_ìˆ˜']):\n",
    "    master_clean['ì„±ë¹„_ê· í˜•ë„'] = (1 - abs(master_clean['ë‚¨ì„±_ìœ ë™ì¸êµ¬_ìˆ˜'] - \n",
    "                                        master_clean['ì—¬ì„±_ìœ ë™ì¸êµ¬_ìˆ˜']) / \n",
    "                                  master_clean['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'])\n",
    "    master_clean['ì„±ë¹„_ê· í˜•ë„'] = master_clean['ì„±ë¹„_ê· í˜•ë„'].fillna(0.5)\n",
    "    print(f\"   âœ… ì„±ë¹„ ê· í˜•ë„: í‰ê·  {master_clean['ì„±ë¹„_ê· í˜•ë„'].mean():.1%}\")\n",
    "\n",
    "print(f\"   âœ… ì£¼ë¥˜ì¹œí™” ì§€ìˆ˜: í‰ê·  {master_clean['ì£¼ë¥˜ì¹œí™”_ì§€ìˆ˜'].mean():.2f}\")\n",
    "\n",
    "# 3. ì ìˆ˜í™” (1-5ì )\n",
    "print(f\"\\n3ï¸âƒ£ ì ìˆ˜í™” (1-5ì ):\")\n",
    "\n",
    "scoring_cols = ['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24', 'ì´_ë§¤ì¶œ', 'ì£¼ë¥˜ì¹œí™”_ì§€ìˆ˜']\n",
    "available_scoring_cols = [col for col in scoring_cols if col in master_clean.columns]\n",
    "\n",
    "for col in available_scoring_cols:\n",
    "    score_col = f'{col}_ì ìˆ˜'\n",
    "    try:\n",
    "        master_clean[score_col] = pd.qcut(master_clean[col].fillna(0), \n",
    "                                         q=5, labels=[1,2,3,4,5], \n",
    "                                         duplicates='drop').astype(float)\n",
    "        print(f\"   âœ… {col} â†’ {score_col}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ {col} ì ìˆ˜í™” ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ—ºï¸ ì§€ë¦¬ì •ë³´ GeoDataFrame ìƒì„±\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ—ºï¸ ì§€ë¦¬ì •ë³´ GeoDataFrame ìƒì„±\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if lng_col and lat_col:\n",
    "    try:\n",
    "        import geopandas as gpd\n",
    "        from shapely.geometry import Point\n",
    "        \n",
    "        # ìœ íš¨í•œ ì¢Œí‘œ ë°ì´í„° í•„í„°ë§\n",
    "        valid_coords = (master_clean[lng_col].notna() & \n",
    "                       master_clean[lat_col].notna())\n",
    "        \n",
    "        geo_data = master_clean[valid_coords].copy()\n",
    "        \n",
    "        # Point ì§€ì˜¤ë©”íŠ¸ë¦¬ ìƒì„±\n",
    "        geometry = [Point(lng, lat) for lng, lat in \n",
    "                   zip(geo_data[lng_col], geo_data[lat_col])]\n",
    "        \n",
    "        # GeoDataFrame ìƒì„±\n",
    "        master_gdf = gpd.GeoDataFrame(geo_data, geometry=geometry, crs='EPSG:4326')\n",
    "        \n",
    "        print(f\"   âœ… GeoDataFrame ìƒì„±: {len(master_gdf):,}ê°œ ìƒê¶Œ\")\n",
    "        print(f\"   ğŸ“ ì¢Œí‘œê³„: EPSG:4326 (WGS84)\")\n",
    "        print(f\"   ğŸ“Š ì§€ë¦¬ì •ë³´ ë¹„ìœ¨: {len(master_gdf)/len(master_clean):.1%}\")\n",
    "        \n",
    "        # GPKG ì €ì¥\n",
    "        output_path = DATA_PATH / \"processed\"\n",
    "        output_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        gpkg_file = output_path / \"seoul_gopchang_master_clean.gpkg\"\n",
    "        master_gdf.to_file(gpkg_file, driver='GPKG')\n",
    "        print(f\"   ğŸ’¾ GeoPackage ì €ì¥: {gpkg_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ GeoDataFrame ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        master_gdf = None\n",
    "else:\n",
    "    print(f\"   âš ï¸ ì¢Œí‘œ ì •ë³´ ë¶€ì¡± - GeoPackage ìƒì„± ë¶ˆê°€\")\n",
    "    master_gdf = None\n",
    "\n",
    "# CSV ì €ì¥\n",
    "csv_file = DATA_PATH / \"processed\" / \"seoul_gopchang_master_clean.csv\"\n",
    "master_clean.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"   ğŸ’¾ CSV ì €ì¥: {csv_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ“Š ì •ì œ ê²°ê³¼ ê²€ì¦ ë° ì‹œê°í™”\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ“Š ì •ì œ ê²°ê³¼ ê²€ì¦ ë° ì‹œê°í™”\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. ê¸°ë³¸ í†µê³„\n",
    "print(\"1ï¸âƒ£ ì •ì œ í›„ ê¸°ë³¸ í†µê³„:\")\n",
    "print(f\"   ğŸ“Š ì´ ìƒê¶Œ ìˆ˜: {len(master_clean):,}ê°œ\")\n",
    "print(f\"   ğŸ“‹ ì´ ì»¬ëŸ¼ ìˆ˜: {len(master_clean.columns)}ê°œ\")\n",
    "print(f\"   ğŸŒ™ ì•¼ê°„ ë°ì´í„°: {master_clean['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24'].notna().sum():,}ê°œ\")\n",
    "print(f\"   ğŸ’° ë§¤ì¶œ ë°ì´í„°: {master_clean['ì´_ë§¤ì¶œ'].notna().sum():,}ê°œ\")\n",
    "print(f\"   ğŸ—ºï¸ ì¢Œí‘œ ë°ì´í„°: {len(master_gdf) if master_gdf is not None else 0:,}ê°œ\")\n",
    "\n",
    "# 2. ì•¼ê°„ ìœ ë™ì¸êµ¬ TOP 10 (ì •ì œ í›„)\n",
    "print(f\"\\n2ï¸âƒ£ ì•¼ê°„ ìœ ë™ì¸êµ¬ TOP 10 (ì •ì œ í›„):\")\n",
    "if 'ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24' in master_clean.columns and 'ìƒê¶Œ_ì½”ë“œ_ëª…' in master_clean.columns:\n",
    "    top_clean = master_clean.nlargest(10, 'ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24')[\n",
    "        ['ìƒê¶Œ_ì½”ë“œ_ëª…', 'ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24', 'ì´_ë§¤ì¶œ']\n",
    "    ]\n",
    "    for i, (idx, row) in enumerate(top_clean.iterrows(), 1):\n",
    "        sales_info = f\"{row['ì´_ë§¤ì¶œ']/1e8:.1f}ì–µì›\" if pd.notna(row['ì´_ë§¤ì¶œ']) else \"N/A\"\n",
    "        print(f\"   {i:2d}. {row['ìƒê¶Œ_ì½”ë“œ_ëª…']:20s}: {row['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24']:7,.0f}ëª… ({sales_info})\")\n",
    "\n",
    "# 3. ë°ì´í„° í’ˆì§ˆ ë¹„êµ (ì •ì œ ì „í›„)\n",
    "print(f\"\\n3ï¸âƒ£ ë°ì´í„° í’ˆì§ˆ ë¹„êµ:\")\n",
    "print(f\"   ğŸ“Š ì •ì œ ì „: 471,240ê°œ â†’ ì •ì œ í›„: {len(master_clean):,}ê°œ\")\n",
    "print(f\"   ğŸ“‰ ë°ì´í„° í¬ê¸° ê°ì†Œ: {(1 - len(master_clean)/471240)*100:.1f}%\")\n",
    "print(f\"   âœ… ì •ìƒ ìƒê¶Œ ìˆ˜ ë‹¬ì„±: {len(master_clean) == 1650}\")\n",
    "\n",
    "# 4. ì‹œê°í™”\n",
    "fig_summary = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('ì •ì œ ì „í›„ ë¹„êµ', 'ì•¼ê°„ ìœ ë™ì¸êµ¬ ë¶„í¬', 'ë§¤ì¶œ íš¨ìœ¨ì„±', 'ë°ì´í„° ì™„ì„±ë„'),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"histogram\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# 4-1. ì •ì œ ì „í›„ ë¹„êµ\n",
    "fig_summary.add_trace(\n",
    "    go.Bar(x=['ì •ì œ ì „', 'ì •ì œ í›„'], y=[471240, len(master_clean)],\n",
    "           marker_color=['lightcoral', 'lightgreen'],\n",
    "           text=['471Kê°œ', f'{len(master_clean):,}ê°œ'],\n",
    "           textposition='outside'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 4-2. ì•¼ê°„ ìœ ë™ì¸êµ¬ ë¶„í¬\n",
    "if 'ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24' in master_clean.columns:\n",
    "    night_data = master_clean['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24'].dropna()\n",
    "    fig_summary.add_trace(\n",
    "        go.Histogram(x=night_data, nbinsx=30, marker_color='lightblue'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# 4-3. ë§¤ì¶œ íš¨ìœ¨ì„± (ì•¼ê°„ ì¸êµ¬ vs ë§¤ì¶œ)\n",
    "if all(col in master_clean.columns for col in ['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24', 'ì´_ë§¤ì¶œ']):\n",
    "    clean_data = master_clean[['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24', 'ì´_ë§¤ì¶œ']].dropna()\n",
    "    if len(clean_data) > 0:\n",
    "        fig_summary.add_trace(\n",
    "            go.Scatter(x=clean_data['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24'], \n",
    "                      y=clean_data['ì´_ë§¤ì¶œ'],\n",
    "                      mode='markers', marker_color='orange', opacity=0.6),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "# 4-4. ë°ì´í„° ì™„ì„±ë„\n",
    "completeness = {}\n",
    "key_cols = ['ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24', 'ì´_ë§¤ì¶œ', 'ì´_ìƒì£¼ì¸êµ¬']\n",
    "for col in key_cols:\n",
    "    if col in master_clean.columns:\n",
    "        completeness[col] = (master_clean[col].notna().sum() / len(master_clean)) * 100\n",
    "\n",
    "if completeness:\n",
    "    fig_summary.add_trace(\n",
    "        go.Bar(x=list(completeness.keys()), y=list(completeness.values()),\n",
    "               marker_color='lightgreen',\n",
    "               text=[f'{v:.1f}%' for v in completeness.values()],\n",
    "               textposition='outside'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "fig_summary.update_layout(\n",
    "    title=\"ğŸ§¹ ë°ì´í„° ì •ì œ ê²°ê³¼ ìš”ì•½\",\n",
    "    height=800,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig_summary.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ğŸ¯ ì™„ë£Œ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "# ================================================================================\n",
    "\n",
    "print(\"ğŸ¯ ë°ì´í„° ì •ì œ ì™„ë£Œ!\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(f\"âœ… ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ìµœì¢… ì •ì œ ê²°ê³¼:\")\n",
    "print(f\"   ğŸ—ƒï¸  ê¹”ë”í•œ ë§ˆìŠ¤í„° ë°ì´í„°: {master_clean.shape}\")\n",
    "print(f\"   ğŸŒ™ ì•¼ê°„ ìœ ë™ì¸êµ¬: {master_clean['ì•¼ê°„_ìœ ë™ì¸êµ¬_17_24'].notna().sum():,}ê°œ ìƒê¶Œ\")\n",
    "print(f\"   ğŸ’° ë§¤ì¶œ ë°ì´í„°: {master_clean['ì´_ë§¤ì¶œ'].notna().sum():,}ê°œ ìƒê¶Œ\")\n",
    "print(f\"   ğŸ—ºï¸ ì§€ë¦¬ì •ë³´: {len(master_gdf) if master_gdf is not None else 0:,}ê°œ ìƒê¶Œ\")\n",
    "print(f\"   ğŸ’¾ ì €ì¥ íŒŒì¼: seoul_gopchang_master_clean.csv / .gpkg\")\n",
    "\n",
    "print(f\"\\nğŸ¯ í•´ê²°ëœ ë¬¸ì œë“¤:\")\n",
    "print(f\"   âœ… ì—…ì¢…ë³„ ì¤‘ë³µ ì œê±°: 471K â†’ {len(master_clean):,}ê°œ\")\n",
    "print(f\"   âœ… ì •í™•í•œ ìƒê¶Œ ìˆ˜: {len(master_clean) == 1650}\")\n",
    "print(f\"   âœ… ì¢Œí‘œ ì •ë³´ ë³µêµ¬: {len(master_gdf) if master_gdf is not None else 0}ê°œ ìƒê¶Œ\")\n",
    "print(f\"   âœ… ì˜¬ë°”ë¥¸ TOP ìƒê¶Œ í™•ì¸\")\n",
    "\n",
    "print(f\"\\nğŸš€ ì´ì œ ì¤€ë¹„ëœ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(f\"   A. KPI ìŠ¤ì½”ì–´ë§ (ê²½ìŸë°€ë„, í†µí•©ì ìˆ˜) â­ ì¶”ì²œ\")\n",
    "print(f\"   B. ì§€ë„ ì‹œê°í™” (Folium + ì¢Œí‘œ)\")\n",
    "print(f\"   C. ìƒê¶Œë³„ ìƒì„¸ ë¶„ì„ (TOP 30)\")\n",
    "print(f\"   D. ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ§¹ ë°ì´í„° ì •ì œ ì™„ë£Œ!\")\n",
    "print(\"ğŸ¯ ì´ì œ ê¹”ë”í•œ ë°ì´í„°ë¡œ ë³¸ê²©ì ì¸ ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
