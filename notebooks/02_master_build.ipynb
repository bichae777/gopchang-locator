{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 셀에서 실행\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    print(\"✅ GeoPandas 준비됨\")\n",
    "except ImportError:\n",
    "    print(\"❌ GeoPandas 설치 필요\")\n",
    "    # conda install -c conda-forge geopandas\n",
    "\n",
    "try:\n",
    "    from shapely.geometry import Point\n",
    "    print(\"✅ Shapely 준비됨\")\n",
    "except ImportError:\n",
    "    print(\"❌ Shapely 설치 필요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 셀에서 실행 - 각 데이터셋의 실제 컬럼명 확인\n",
    "print(\"📋 각 데이터셋의 상권 관련 컬럼 확인:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "datasets_check = {\n",
    "    'boundary': boundary_df,\n",
    "    'flow_latest': flow_latest, \n",
    "    'resident_latest': resident_latest,\n",
    "    'sales_latest': sales_latest,\n",
    "    'income_latest': income_latest,\n",
    "    'facility_latest': facility_latest\n",
    "}\n",
    "\n",
    "for name, df in datasets_check.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    # 상권 관련 컬럼 찾기\n",
    "    district_cols = [col for col in df.columns if any(keyword in col \n",
    "                    for keyword in ['상권', 'TRDAR', '코드', 'CD', 'CODE'])]\n",
    "    print(f\"  상권 관련 컬럼: {district_cols}\")\n",
    "    \n",
    "    # 첫 5개 컬럼만 표시\n",
    "    print(f\"  전체 컬럼 (앞 5개): {list(df.columns)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 확인할 변수명 매핑 (키: 여러분이 부르고 싶은 이름, 값: 실제 변수명)\n",
    "vars_to_check = {\n",
    "    'boundary': 'boundary_df',\n",
    "    'flow_latest': 'flow_latest',\n",
    "    'resident_latest': 'resident_latest',\n",
    "    'sales_latest': 'sales_latest',\n",
    "    'income_latest': 'income_latest',\n",
    "    'facility_latest': 'facility_latest'\n",
    "}\n",
    "\n",
    "# 2) 존재 여부, 타입, shape, columns 출력\n",
    "for key, var_name in vars_to_check.items():\n",
    "    if var_name in globals():\n",
    "        df = globals()[var_name]\n",
    "        try:\n",
    "            rows, cols = df.shape\n",
    "            print(f\"✅ {key} ({var_name}): {type(df).__name__}, shape={rows}×{cols}\")\n",
    "            print(\"   columns:\", df.columns.tolist())\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {key} ({var_name}): 변수는 존재하지만 .shape/.columns를 읽을 수 없습니다 ({e})\")\n",
    "    else:\n",
    "        print(f\"❌ {key}: 변수 `{var_name}` 가 정의되지 않았습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 셀에서 실행 - 개선된 상권코드 통일 함수\n",
    "def standardize_district_code_fixed(df, dataset_name):\n",
    "    \"\"\"상권코드 컬럼을 TRDAR_CD로 통일 (실제 컬럼명 기반)\"\"\"\n",
    "    \n",
    "    # 데이터셋별 매핑 규칙\n",
    "    column_mapping = {\n",
    "        'boundary': '상권_코드',\n",
    "        'flow': '상권_코드', \n",
    "        'resident': 'market_code',      # ← 이게 핵심!\n",
    "        'sales': '상권_코드',\n",
    "        'income': '상권_코드',\n",
    "        'facility': '상권배후지_코드'    # ← 이것도!\n",
    "    }\n",
    "    \n",
    "    target_col = column_mapping.get(dataset_name, '상권_코드')\n",
    "    \n",
    "    if target_col in df.columns:\n",
    "        df['TRDAR_CD'] = df[target_col]\n",
    "        print(f\"✅ {dataset_name}: {target_col} → TRDAR_CD\")\n",
    "        return True\n",
    "    else:\n",
    "        # 백업 방법들\n",
    "        possible_cols = ['TRDAR_CD', '상권_코드', 'market_code', '상권배후지_코드']\n",
    "        for col in possible_cols:\n",
    "            if col in df.columns:\n",
    "                if col != 'TRDAR_CD':\n",
    "                    df['TRDAR_CD'] = df[col]\n",
    "                print(f\"✅ {dataset_name}: {col} → TRDAR_CD (백업)\")\n",
    "                return True\n",
    "    \n",
    "    print(f\"❌ {dataset_name}: 상권코드 컬럼을 찾을 수 없음\")\n",
    "    return False\n",
    "\n",
    "# 테스트\n",
    "print(\"🧪 상권코드 통일 테스트:\")\n",
    "standardize_district_code_fixed(resident_latest, 'resident')\n",
    "standardize_district_code_fixed(facility_latest, 'facility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏗️ 곱창집 입지 분석 마스터 데이터셋 구축\n",
    "# 02_master_build.ipynb\n",
    "# \n",
    "# 목적: 모든 데이터를 TRDAR_CD 기준으로 통합하여 \n",
    "#       seoul_gopchang_master.gpkg 마스터 데이터셋 생성\n",
    "\n",
    "# ================================================================================\n",
    "# 📚 라이브러리 임포트\n",
    "# ================================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"🏗️ 곱창집 입지 분석 마스터 데이터셋 구축 시작!\")\n",
    "print(f\"⏰ 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 📂 모든 데이터 로드\n",
    "# ================================================================================\n",
    "\n",
    "print(\"📂 모든 데이터 로드 중...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 데이터 경로 설정\n",
    "DATA_PATH = Path(\"../data\")\n",
    "RAW_PATH = DATA_PATH / \"raw\"\n",
    "\n",
    "# 데이터 로드 상태 추적\n",
    "data_status = {}\n",
    "\n",
    "try:\n",
    "    # 1. 상권 경계 데이터 (GIS 기준점)\n",
    "    print(\"1️⃣ 상권 경계 데이터 로드...\")\n",
    "    boundary_df = pd.read_csv(DATA_PATH / \"boundary/boundary_all.csv\", encoding='utf-8')\n",
    "    data_status['boundary'] = f\"✅ 성공 ({boundary_df.shape})\"\n",
    "    print(f\"   📍 상권 경계: {boundary_df.shape}\")\n",
    "    \n",
    "    # 2. 유동인구 데이터 (야간 분석 완료)\n",
    "    print(\"2️⃣ 유동인구 데이터 로드...\")\n",
    "    flow_df = pd.read_csv(RAW_PATH / \"flow/flow_all.csv\", encoding='utf-8')\n",
    "    data_status['flow'] = f\"✅ 성공 ({flow_df.shape})\"\n",
    "    print(f\"   👥 유동인구: {flow_df.shape}\")\n",
    "    \n",
    "    # 3. 상주인구 데이터\n",
    "    print(\"3️⃣ 상주인구 데이터 로드...\")\n",
    "    resident_df = pd.read_csv(RAW_PATH / \"resident/resident_all.csv\", encoding='utf-8')\n",
    "    data_status['resident'] = f\"✅ 성공 ({resident_df.shape})\"\n",
    "    print(f\"   🏠 상주인구: {resident_df.shape}\")\n",
    "    \n",
    "    # 4. 추정매출 데이터\n",
    "    print(\"4️⃣ 추정매출 데이터 로드...\")\n",
    "    sales_df = pd.read_csv(RAW_PATH / \"sales/sales_all.csv\", encoding='utf-8')\n",
    "    data_status['sales'] = f\"✅ 성공 ({sales_df.shape})\"\n",
    "    print(f\"   💰 추정매출: {sales_df.shape}\")\n",
    "    \n",
    "    # 5. 소득·소비 데이터\n",
    "    print(\"5️⃣ 소득·소비 데이터 로드...\")\n",
    "    income_df = pd.read_csv(RAW_PATH / \"income_exp/income_all.csv\", encoding='utf-8')\n",
    "    data_status['income'] = f\"✅ 성공 ({income_df.shape})\"\n",
    "    print(f\"   💳 소득·소비: {income_df.shape}\")\n",
    "    \n",
    "    # 6. 집객시설 데이터\n",
    "    print(\"6️⃣ 집객시설 데이터 로드...\")\n",
    "    facility_df = pd.read_csv(RAW_PATH / \"facility/facility_all.csv\", encoding='utf-8')\n",
    "    data_status['facility'] = f\"✅ 성공 ({facility_df.shape})\"\n",
    "    print(f\"   🏢 집객시설: {facility_df.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 데이터 로드 오류: {e}\")\n",
    "    data_status['error'] = str(e)\n",
    "\n",
    "print(f\"\\n📊 총 {len([k for k, v in data_status.items() if '✅' in v])}개 데이터셋 로드 완료\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🔍 데이터 구조 및 품질 분석\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🔍 데이터 구조 및 품질 분석\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 각 데이터셋별 TRDAR_CD (상권코드) 분석\n",
    "datasets = {\n",
    "    'boundary': boundary_df,\n",
    "    'flow': flow_df, \n",
    "    'resident': resident_df,\n",
    "    'sales': sales_df,\n",
    "    'income': income_df,\n",
    "    'facility': facility_df\n",
    "}\n",
    "\n",
    "trdar_analysis = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    if 'TRDAR_CD' in df.columns or '상권_코드' in df.columns:\n",
    "        # 상권코드 컬럼 찾기\n",
    "        trdar_col = 'TRDAR_CD' if 'TRDAR_CD' in df.columns else '상권_코드'\n",
    "        \n",
    "        unique_codes = df[trdar_col].nunique()\n",
    "        total_rows = len(df)\n",
    "        latest_quarter = df['기준_년분기_코드'].max() if '기준_년분기_코드' in df.columns else 'N/A'\n",
    "        \n",
    "        trdar_analysis[name] = {\n",
    "            'unique_districts': unique_codes,\n",
    "            'total_rows': total_rows,\n",
    "            'latest_quarter': latest_quarter,\n",
    "            'trdar_column': trdar_col\n",
    "        }\n",
    "        \n",
    "        print(f\"📋 {name:10s}: {unique_codes:4d}개 상권, {total_rows:6d}행, 최신분기: {latest_quarter}\")\n",
    "\n",
    "print(f\"\\n🎯 기준 상권 수 (boundary): {trdar_analysis['boundary']['unique_districts']}개\")\n",
    "\n",
    "# 기준년분기 통일 분석\n",
    "print(f\"\\n📅 기준년분기 분석:\")\n",
    "for name, df in datasets.items():\n",
    "    if '기준_년분기_코드' in df.columns:\n",
    "        quarters = sorted(df['기준_년분기_코드'].unique(), reverse=True)\n",
    "        print(f\"   {name:10s}: {quarters[:3]}... (총 {len(quarters)}개 분기)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# ⚙️ 데이터 전처리 및 통합 준비\n",
    "# ================================================================================\n",
    "\n",
    "print(\"⚙️ 데이터 전처리 및 통합 준비\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 최신 분기 데이터 추출 함수\n",
    "def get_latest_quarter_data(df, name):\n",
    "    \"\"\"최신 분기 데이터만 추출\"\"\"\n",
    "    if '기준_년분기_코드' not in df.columns:\n",
    "        print(f\"   {name}: 기준년분기 없음 (전체 데이터 사용)\")\n",
    "        return df\n",
    "    \n",
    "    latest_quarter = df['기준_년분기_코드'].max()\n",
    "    latest_df = df[df['기준_년분기_코드'] == latest_quarter].copy()\n",
    "    \n",
    "    print(f\"   {name}: {latest_quarter} → {len(latest_df):,}행\")\n",
    "    return latest_df\n",
    "\n",
    "# 2. 최신 분기 데이터 추출\n",
    "print(\"📅 최신 분기 데이터 추출:\")\n",
    "\n",
    "flow_latest = get_latest_quarter_data(flow_df, 'flow')\n",
    "resident_latest = get_latest_quarter_data(resident_df, 'resident') \n",
    "sales_latest = get_latest_quarter_data(sales_df, 'sales')\n",
    "income_latest = get_latest_quarter_data(income_df, 'income')\n",
    "facility_latest = get_latest_quarter_data(facility_df, 'facility')\n",
    "\n",
    "# 3. 야간 유동인구 계산 (이전 분석 결과 적용)\n",
    "print(f\"\\n🌙 야간 유동인구 계산 (17-24시 기준):\")\n",
    "\n",
    "def calculate_night_flow(df):\n",
    "    \"\"\"17-24시 야간 유동인구 계산\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 17-24시 = 17-21시 + 21-24시\n",
    "    df['야간_유동인구_17_24'] = (df['시간대_17_21_유동인구_수'] + \n",
    "                               df['시간대_21_24_유동인구_수'])\n",
    "    \n",
    "    # 추가 야간 지표들\n",
    "    df['야간_비율'] = df['야간_유동인구_17_24'] / df['총_유동인구_수']\n",
    "    df['주말_평균'] = (df['토요일_유동인구_수'] + df['일요일_유동인구_수']) / 2\n",
    "    df['주중_평균'] = (df['월요일_유동인구_수'] + df['화요일_유동인구_수'] + \n",
    "                     df['수요일_유동인구_수'] + df['목요일_유동인구_수'] + \n",
    "                     df['금요일_유동인구_수']) / 5\n",
    "    df['주말_프리미엄'] = df['주말_평균'] / df['주중_평균']\n",
    "    \n",
    "    return df\n",
    "\n",
    "flow_latest = calculate_night_flow(flow_latest)\n",
    "print(f\"   ✅ 야간 유동인구 계산 완료\")\n",
    "print(f\"   📊 평균 야간 유동인구: {flow_latest['야간_유동인구_17_24'].mean():,.0f}명\")\n",
    "print(f\"   📊 평균 야간 비율: {flow_latest['야간_비율'].mean():.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🔗 마스터 데이터셋 구축 (단계별 조인)\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🔗 마스터 데이터셋 구축 (단계별 조인)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 기준 데이터: 상권 경계 (boundary)\n",
    "print(\"1️⃣ 기준 데이터 설정: 상권 경계\")\n",
    "master_df = boundary_df.copy()\n",
    "\n",
    "# 상권코드 컬럼 통일\n",
    "if '상권_코드' in master_df.columns:\n",
    "    master_df['TRDAR_CD'] = master_df['상권_코드']\n",
    "\n",
    "print(f\"   📍 기준 상권 수: {len(master_df):,}개\")\n",
    "\n",
    "# 2. 유동인구 데이터 조인\n",
    "print(f\"\\n2️⃣ 유동인구 데이터 조인:\")\n",
    "before_count = len(master_df)\n",
    "\n",
    "# 상권코드 컬럼 통일 함수\n",
    "def standardize_district_code(df, dataset_name):\n",
    "    \"\"\"상권코드 컬럼을 TRDAR_CD로 통일 (데이터셋별 매핑)\"\"\"\n",
    "    \n",
    "    # 데이터셋별 실제 컬럼명 매핑\n",
    "    column_mapping = {\n",
    "        'boundary': '상권_코드',\n",
    "        'flow': '상권_코드', \n",
    "        'resident': 'market_code',      # resident는 market_code 사용\n",
    "        'sales': '상권_코드',\n",
    "        'income': '상권_코드',\n",
    "        'facility': '상권배후지_코드'    # facility는 상권배후지_코드 사용\n",
    "    }\n",
    "    \n",
    "    # 우선순위: 매핑된 컬럼 → 기본 후보들\n",
    "    target_col = column_mapping.get(dataset_name, '상권_코드')\n",
    "    fallback_cols = ['TRDAR_CD', '상권_코드', 'market_code', '상권배후지_코드', 'DISTRICT_CD']\n",
    "    \n",
    "    # 1차: 매핑된 컬럼 시도\n",
    "    if target_col in df.columns:\n",
    "        if target_col != 'TRDAR_CD':\n",
    "            df['TRDAR_CD'] = df[target_col]\n",
    "        print(f\"   📋 {dataset_name} 상권코드: {target_col} → TRDAR_CD\")\n",
    "        return True\n",
    "    \n",
    "    # 2차: 백업 컬럼들 시도\n",
    "    for col in fallback_cols:\n",
    "        if col in df.columns:\n",
    "            if col != 'TRDAR_CD':\n",
    "                df['TRDAR_CD'] = df[col]\n",
    "            print(f\"   📋 {dataset_name} 상권코드: {col} → TRDAR_CD (백업)\")\n",
    "            return True\n",
    "    \n",
    "    print(f\"   ❌ {dataset_name}: 상권코드 컬럼을 찾을 수 없음\")\n",
    "    print(f\"   📋 사용 가능한 컬럼: {list(df.columns)[:10]}\")\n",
    "    return False\n",
    "\n",
    "# 유동인구 데이터 상권코드 통일\n",
    "if standardize_district_code(flow_latest, 'flow'):\n",
    "    # 핵심 유동인구 컬럼만 선택\n",
    "    flow_cols = ['TRDAR_CD', '총_유동인구_수', '야간_유동인구_17_24', '야간_비율',\n",
    "                 '주말_평균', '주중_평균', '주말_프리미엄',\n",
    "                 '남성_유동인구_수', '여성_유동인구_수',\n",
    "                 '연령대_20_유동인구_수', '연령대_30_유동인구_수', '연령대_40_유동인구_수']\n",
    "    \n",
    "    # 실제 존재하는 컬럼만 선택\n",
    "    available_flow_cols = [col for col in flow_cols if col in flow_latest.columns]\n",
    "    flow_selected = flow_latest[available_flow_cols].copy()\n",
    "    \n",
    "    master_df = master_df.merge(flow_selected, on='TRDAR_CD', how='left')\n",
    "    after_count = len(master_df)\n",
    "    \n",
    "    print(f\"   📊 조인 전: {before_count:,}개 → 조인 후: {after_count:,}개\")\n",
    "    print(f\"   📈 유동인구 매칭률: {(master_df['총_유동인구_수'].notna().sum() / len(master_df)):.1%}\")\n",
    "else:\n",
    "    print(f\"   ⚠️ 유동인구 데이터 조인 건너뜀\")\n",
    "\n",
    "# 3. 상주인구 데이터 조인\n",
    "print(f\"\\n3️⃣ 상주인구 데이터 조인:\")\n",
    "\n",
    "if standardize_district_code(resident_latest, 'resident'):\n",
    "    # 상주인구 관련 컬럼 찾기\n",
    "    resident_pop_cols = [col for col in resident_latest.columns if '인구' in col]\n",
    "    print(f\"   📋 상주인구 관련 컬럼: {resident_pop_cols[:5]}\")\n",
    "    \n",
    "    if resident_pop_cols:\n",
    "        # 첫 번째 인구 관련 컬럼을 상주인구로 사용\n",
    "        main_resident_col = resident_pop_cols[0]\n",
    "        resident_latest['상주인구_수'] = resident_latest[main_resident_col]\n",
    "        print(f\"   📋 사용할 상주인구 컬럼: {main_resident_col}\")\n",
    "        \n",
    "        resident_selected = resident_latest[['TRDAR_CD', '상주인구_수']].copy()\n",
    "        master_df = master_df.merge(resident_selected, on='TRDAR_CD', how='left')\n",
    "        \n",
    "        print(f\"   📈 상주인구 매칭률: {(master_df['상주인구_수'].notna().sum() / len(master_df)):.1%}\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ 상주인구 컬럼을 찾을 수 없음\")\n",
    "else:\n",
    "    print(f\"   ⚠️ 상주인구 데이터 조인 건너뜀\")\n",
    "\n",
    "# 4. 추정매출 데이터 조인\n",
    "print(f\"\\n4️⃣ 추정매출 데이터 조인:\")\n",
    "\n",
    "if standardize_district_code(sales_latest, 'sales'):\n",
    "    # 추정매출 관련 컬럼 찾기\n",
    "    sales_cols = [col for col in sales_latest.columns if '매출' in col or 'SAL' in col or 'SALES' in col]\n",
    "    print(f\"   📋 매출 관련 컬럼: {sales_cols[:5]}\")\n",
    "    \n",
    "    if sales_cols:\n",
    "        main_sales_col = sales_cols[0]\n",
    "        sales_latest['추정매출'] = sales_latest[main_sales_col]\n",
    "        print(f\"   📋 사용할 매출 컬럼: {main_sales_col}\")\n",
    "        \n",
    "        sales_selected = sales_latest[['TRDAR_CD', '추정매출']].copy()\n",
    "        master_df = master_df.merge(sales_selected, on='TRDAR_CD', how='left')\n",
    "        \n",
    "        print(f\"   📈 추정매출 매칭률: {(master_df['추정매출'].notna().sum() / len(master_df)):.1%}\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ 매출 컬럼을 찾을 수 없음\")\n",
    "else:\n",
    "    print(f\"   ⚠️ 추정매출 데이터 조인 건너뜀\")\n",
    "\n",
    "# 5. 소득·소비 데이터 조인\n",
    "print(f\"\\n5️⃣ 소득·소비 데이터 조인:\")\n",
    "\n",
    "if standardize_district_code(income_latest, 'income'):\n",
    "    # 소득·소비 관련 컬럼 찾기\n",
    "    income_cols = [col for col in income_latest.columns if '소득' in col or 'INCOME' in col]\n",
    "    expense_cols = [col for col in income_latest.columns if '소비' in col or 'EXPEND' in col]\n",
    "    \n",
    "    print(f\"   📋 소득 관련 컬럼: {income_cols[:3]}\")\n",
    "    print(f\"   📋 소비 관련 컬럼: {expense_cols[:3]}\")\n",
    "    \n",
    "    income_data = {}\n",
    "    if income_cols:\n",
    "        income_data['평균소득'] = income_latest[income_cols[0]]\n",
    "    if expense_cols:\n",
    "        income_data['평균소비'] = income_latest[expense_cols[0]]\n",
    "    \n",
    "    if income_data:\n",
    "        income_selected = pd.DataFrame({'TRDAR_CD': income_latest['TRDAR_CD']})\n",
    "        for key, series in income_data.items():\n",
    "            income_selected[key] = series\n",
    "        \n",
    "        master_df = master_df.merge(income_selected, on='TRDAR_CD', how='left')\n",
    "        print(f\"   📈 소득·소비 매칭률: {(master_df[list(income_data.keys())[0]].notna().sum() / len(master_df)):.1%}\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ 소득·소비 컬럼을 찾을 수 없음\")\n",
    "else:\n",
    "    print(f\"   ⚠️ 소득·소비 데이터 조인 건너뜀\")\n",
    "\n",
    "print(f\"\\n🎯 마스터 데이터셋 기본 구축 완료: {master_df.shape}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 📊 파생지표 생성\n",
    "# ================================================================================\n",
    "\n",
    "print(\"📊 곱창집 특화 파생지표 생성\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 인구밀도 지표\n",
    "print(\"1️⃣ 인구밀도 지표:\")\n",
    "master_df['유동밀도_점수'] = pd.qcut(master_df['총_유동인구_수'].fillna(0), \n",
    "                                  q=5, labels=[1,2,3,4,5]).astype(float)\n",
    "\n",
    "master_df['야간밀도_점수'] = pd.qcut(master_df['야간_유동인구_17_24'].fillna(0), \n",
    "                                   q=5, labels=[1,2,3,4,5]).astype(float)\n",
    "\n",
    "print(f\"   ✅ 유동밀도 점수: 1(최저) ~ 5(최고)\")\n",
    "print(f\"   ✅ 야간밀도 점수: 1(최저) ~ 5(최고)\")\n",
    "\n",
    "# 2. 매출 효율성 지표\n",
    "print(f\"\\n2️⃣ 매출 효율성 지표:\")\n",
    "master_df['총인구'] = master_df['총_유동인구_수'].fillna(0) + master_df['상주인구_수'].fillna(0)\n",
    "\n",
    "# 인구 1명당 추정매출\n",
    "master_df['인당_매출효율'] = master_df['추정매출'] / master_df['총인구']\n",
    "master_df['인당_매출효율'] = master_df['인당_매출효율'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 야간 특화 효율성\n",
    "master_df['야간_매출효율'] = master_df['추정매출'] / master_df['야간_유동인구_17_24']\n",
    "master_df['야간_매출효율'] = master_df['야간_매출효율'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "print(f\"   ✅ 인당 매출효율: 평균 {master_df['인당_매출효율'].mean():.0f}원/명\")\n",
    "print(f\"   ✅ 야간 매출효율: 평균 {master_df['야간_매출효율'].mean():.0f}원/명\")\n",
    "\n",
    "# 3. 곱창집 특화 지표\n",
    "print(f\"\\n3️⃣ 곱창집 특화 지표:\")\n",
    "\n",
    "# 주류 친화 지표 (야간 + 주말 가중)\n",
    "master_df['주류친화_지수'] = (master_df['야간_비율'].fillna(0) * 0.6 + \n",
    "                           master_df['주말_프리미엄'].fillna(1) * 0.4)\n",
    "\n",
    "# 연령대별 타겟 고객 비율 (20-40대)\n",
    "target_age_cols = ['연령대_20_유동인구_수', '연령대_30_유동인구_수', '연령대_40_유동인구_수']\n",
    "available_age_cols = [col for col in target_age_cols if col in master_df.columns]\n",
    "\n",
    "if available_age_cols:\n",
    "    master_df['타겟연령_비율'] = master_df[available_age_cols].sum(axis=1) / master_df['총_유동인구_수']\n",
    "    master_df['타겟연령_비율'] = master_df['타겟연령_비율'].fillna(0)\n",
    "    print(f\"   ✅ 타겟연령(20-40대) 비율: 평균 {master_df['타겟연령_비율'].mean():.1%}\")\n",
    "\n",
    "# 남녀 비율 균형도 (곱창은 남녀 모두 선호)\n",
    "if all(col in master_df.columns for col in ['남성_유동인구_수', '여성_유동인구_수']):\n",
    "    master_df['성비_균형도'] = 1 - abs(master_df['남성_유동인구_수'] - master_df['여성_유동인구_수']) / master_df['총_유동인구_수']\n",
    "    master_df['성비_균형도'] = master_df['성비_균형도'].fillna(0.5)\n",
    "    print(f\"   ✅ 성비 균형도: 평균 {master_df['성비_균형도'].mean():.1%}\")\n",
    "\n",
    "print(f\"   ✅ 주류친화 지수: 평균 {master_df['주류친화_지수'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\n📊 파생지표 생성 완료: {len([col for col in master_df.columns if '점수' in col or '지수' in col or '효율' in col])}개\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🗺️ 지리정보 처리 및 GeoPackage 생성\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🗺️ 지리정보 처리 및 GeoPackage 생성\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 지리정보 컬럼 확인\n",
    "geo_columns = [col for col in master_df.columns if any(keyword in col.lower() \n",
    "              for keyword in ['경도', 'lng', 'lon', '위도', 'lat', 'x좌표', 'y좌표'])]\n",
    "\n",
    "print(f\"📍 지리정보 컬럼: {geo_columns}\")\n",
    "\n",
    "if len(geo_columns) >= 2:\n",
    "    # 경도/위도 컬럼 식별\n",
    "    lng_col = next((col for col in geo_columns if '경도' in col or 'lng' in col.lower() or 'lon' in col.lower()), geo_columns[0])\n",
    "    lat_col = next((col for col in geo_columns if '위도' in col or 'lat' in col.lower()), geo_columns[1])\n",
    "    \n",
    "    print(f\"   📍 경도 컬럼: {lng_col}\")\n",
    "    print(f\"   📍 위도 컬럼: {lat_col}\")\n",
    "    \n",
    "    # 유효한 좌표 데이터 확인\n",
    "    valid_coords = master_df[lng_col].notna() & master_df[lat_col].notna()\n",
    "    valid_count = valid_coords.sum()\n",
    "    \n",
    "    print(f\"   📊 유효 좌표: {valid_count:,}개 ({valid_count/len(master_df):.1%})\")\n",
    "    \n",
    "    if valid_count > 0:\n",
    "        # GeoDataFrame 생성\n",
    "        geo_master = master_df[valid_coords].copy()\n",
    "        \n",
    "        try:\n",
    "            from shapely.geometry import Point\n",
    "            \n",
    "            # Point 지오메트리 생성\n",
    "            geometry = [Point(lng, lat) for lng, lat in zip(geo_master[lng_col], geo_master[lat_col])]\n",
    "            geo_master_gdf = gpd.GeoDataFrame(geo_master, geometry=geometry, crs='EPSG:4326')\n",
    "            \n",
    "            print(f\"   ✅ GeoDataFrame 생성 성공: {len(geo_master_gdf):,}개 상권\")\n",
    "            \n",
    "            # GeoPackage 저장\n",
    "            output_path = DATA_PATH / \"processed\"\n",
    "            output_path.mkdir(exist_ok=True)\n",
    "            \n",
    "            gpkg_file = output_path / \"seoul_gopchang_master.gpkg\"\n",
    "            geo_master_gdf.to_file(gpkg_file, driver='GPKG')\n",
    "            \n",
    "            print(f\"   💾 GeoPackage 저장: {gpkg_file}\")\n",
    "            print(f\"   📐 좌표계: EPSG:4326 (WGS84)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ GeoDataFrame 생성 실패: {e}\")\n",
    "            geo_master_gdf = None\n",
    "    else:\n",
    "        print(f\"   ⚠️ 유효한 좌표 데이터 부족\")\n",
    "        geo_master_gdf = None\n",
    "else:\n",
    "    print(f\"   ⚠️ 지리정보 컬럼 부족 (CSV만 저장)\")\n",
    "    geo_master_gdf = None\n",
    "\n",
    "# CSV 백업 저장\n",
    "csv_file = DATA_PATH / \"processed\" / \"seoul_gopchang_master.csv\"\n",
    "master_df.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"   💾 CSV 백업 저장: {csv_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 📊 마스터 데이터셋 품질 검증 및 요약\n",
    "# ================================================================================\n",
    "\n",
    "print(\"📊 마스터 데이터셋 품질 검증 및 요약\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 기본 통계\n",
    "print(\"1️⃣ 기본 통계:\")\n",
    "print(f\"   📊 총 상권 수: {len(master_df):,}개\")\n",
    "print(f\"   📋 총 컬럼 수: {len(master_df.columns)}개\")\n",
    "\n",
    "# 2. 핵심 지표별 결측률\n",
    "print(f\"\\n2️⃣ 핵심 지표 결측률:\")\n",
    "key_columns = ['총_유동인구_수', '야간_유동인구_17_24', '상주인구_수', '추정매출']\n",
    "\n",
    "for col in key_columns:\n",
    "    if col in master_df.columns:\n",
    "        missing_rate = master_df[col].isna().sum() / len(master_df)\n",
    "        print(f\"   {col:20s}: {missing_rate:6.1%} 결측\")\n",
    "\n",
    "# 3. 야간 유동인구 분포\n",
    "print(f\"\\n3️⃣ 야간 유동인구 분포 (17-24시):\")\n",
    "if '야간_유동인구_17_24' in master_df.columns:\n",
    "    night_stats = master_df['야간_유동인구_17_24'].describe()\n",
    "    for stat, value in night_stats.items():\n",
    "        if stat in ['mean', 'std', '50%', 'max']:\n",
    "            print(f\"   {stat:8s}: {value:10,.0f}명\")\n",
    "\n",
    "# 4. 상위 상권 미리보기\n",
    "print(f\"\\n4️⃣ 야간 유동인구 TOP 10 상권:\")\n",
    "if '야간_유동인구_17_24' in master_df.columns and '상권_코드_명' in master_df.columns:\n",
    "    top_districts = master_df.nlargest(10, '야간_유동인구_17_24')[['상권_코드_명', '야간_유동인구_17_24']]\n",
    "    for i, (idx, row) in enumerate(top_districts.iterrows(), 1):\n",
    "        print(f\"   {i:2d}. {row['상권_코드_명']:20s}: {row['야간_유동인구_17_24']:7,.0f}명\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 📈 데이터 품질 시각화\n",
    "# ================================================================================\n",
    "\n",
    "print(\"📈 마스터 데이터셋 품질 시각화\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 1. 결측률 히트맵\n",
    "missing_rates = master_df.isnull().sum() / len(master_df)\n",
    "important_cols = missing_rates[missing_rates > 0].head(15)\n",
    "\n",
    "if len(important_cols) > 0:\n",
    "    fig_missing = go.Figure(data=go.Bar(\n",
    "        y=important_cols.index[::-1],  # 역순으로 표시\n",
    "        x=important_cols.values[::-1] * 100,\n",
    "        orientation='h',\n",
    "        marker_color='lightcoral',\n",
    "        text=[f'{val:.1f}%' for val in important_cols.values[::-1] * 100],\n",
    "        textposition='auto'\n",
    "    ))\n",
    "    \n",
    "    fig_missing.update_layout(\n",
    "        title=\"📊 주요 컬럼별 결측률\",\n",
    "        xaxis_title=\"결측률 (%)\",\n",
    "        yaxis_title=\"컬럼명\",\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_missing.show()\n",
    "\n",
    "# 2. 야간 유동인구 분포\n",
    "if '야간_유동인구_17_24' in master_df.columns:\n",
    "    night_flow_clean = master_df['야간_유동인구_17_24'].dropna()\n",
    "    \n",
    "    fig_dist = go.Figure()\n",
    "    \n",
    "    fig_dist.add_trace(go.Histogram(\n",
    "        x=night_flow_clean,\n",
    "        nbinsx=50,\n",
    "        name='야간 유동인구',\n",
    "        marker_color='lightblue',\n",
    "        opacity=0.7\n",
    "    ))\n",
    "    \n",
    "    fig_dist.update_layout(\n",
    "        title=\"🌙 야간 유동인구 분포 (17-24시)\",\n",
    "        xaxis_title=\"야간 유동인구 (명)\",\n",
    "        yaxis_title=\"상권 수\",\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_dist.show()\n",
    "\n",
    "# 3. 종합 대시보드\n",
    "fig_summary = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('데이터 로드 현황', '핵심 지표 통계', '상위 상권 분포', '품질 점수'),\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"table\"}]]\n",
    ")\n",
    "\n",
    "# 3-1. 데이터 로드 성공률\n",
    "success_data = [1 if '✅' in status else 0 for status in data_status.values() if '✅' in status or '❌' in status]\n",
    "success_rate = sum(success_data) / len(success_data) if success_data else 0\n",
    "\n",
    "fig_summary.add_trace(\n",
    "    go.Pie(labels=['성공', '실패'], values=[success_rate, 1-success_rate],\n",
    "           marker_colors=['lightgreen', 'lightcoral']),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 3-2. 핵심 지표 통계\n",
    "key_stats = {}\n",
    "for col in ['총_유동인구_수', '야간_유동인구_17_24', '상주인구_수']:\n",
    "    if col in master_df.columns:\n",
    "        key_stats[col.replace('_', ' ')] = master_df[col].mean()\n",
    "\n",
    "if key_stats:\n",
    "    fig_summary.add_trace(\n",
    "        go.Bar(x=list(key_stats.keys()), y=list(key_stats.values()),\n",
    "               marker_color='lightblue'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# 3-3. 상권 분포 (지역별 - 상권구분코드 기준)\n",
    "if '상권_구분_코드_명' in master_df.columns:\n",
    "    district_counts = master_df['상권_구분_코드_명'].value_counts().head(10)\n",
    "    \n",
    "    fig_summary.add_trace(\n",
    "        go.Scatter(x=list(range(len(district_counts))), y=district_counts.values,\n",
    "                  mode='markers+lines', marker_size=10, marker_color='orange'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# 3-4. 품질 요약 테이블\n",
    "quality_summary = [\n",
    "    ['총 상권 수', f'{len(master_df):,}개'],\n",
    "    ['완전데이터 상권', f'{master_df.dropna().shape[0]:,}개'],\n",
    "    ['야간데이터 보유', f'{master_df[\"야간_유동인구_17_24\"].notna().sum():,}개'],\n",
    "    ['평균 야간 유동인구', f'{master_df[\"야간_유동인구_17_24\"].mean():,.0f}명'],\n",
    "    ['지리정보 보유', f'{valid_count if \"valid_count\" in locals() else 0:,}개']\n",
    "]\n",
    "\n",
    "fig_summary.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(values=['지표', '값'], fill_color='lightblue', align='center'),\n",
    "        cells=dict(values=list(zip(*quality_summary)), fill_color='white', align='center')),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig_summary.update_layout(\n",
    "    title=\"🎯 곱창집 마스터 데이터셋 종합 현황\",\n",
    "    height=800,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig_summary.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ================================================================================\n",
    "# 🎯 완료 및 다음 단계 안내\n",
    "# ================================================================================\n",
    "\n",
    "print(\"🎯 마스터 데이터셋 구축 완료!\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(f\"✅ 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\n📊 최종 결과:\")\n",
    "print(f\"   🗃️  마스터 데이터셋: {master_df.shape}\")\n",
    "print(f\"   🌙 야간 유동인구 (17-24시): {master_df['야간_유동인구_17_24'].notna().sum():,}개 상권\")\n",
    "print(f\"   💾 저장 파일: seoul_gopchang_master.csv / .gpkg\")\n",
    "print(f\"   📐 지리정보: {valid_count if 'valid_count' in locals() else 0:,}개 상권\")\n",
    "\n",
    "print(f\"\\n🎯 다음 단계 옵션:\")\n",
    "print(f\"   A. KPI 스코어링 (경쟁밀도, 임대료, 통합점수)\")\n",
    "print(f\"   B. 상권별 상세 분석 (TOP 30 추출)\")\n",
    "print(f\"   C. 지도 시각화 (Folium 인터랙티브 맵)\")\n",
    "print(f\"   D. 대시보드 구축 (Plotly Dash)\")\n",
    "\n",
    "print(f\"\\n💡 권장: A번 (KPI 스코어링)부터 진행\")\n",
    "print(f\"   이유: 마스터 데이터가 완성되었으니 곱창집 특화 점수 계산 가능\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🏗️ 마스터 데이터셋 구축 완료!\")\n",
    "print(\"🚀 이제 본격적인 입지 분석을 시작할 준비가 되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gopchang-locator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
